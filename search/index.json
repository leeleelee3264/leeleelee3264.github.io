[{"content":"\nCA와 CA에서 Digital Certificate을 발급받아서 적용하는 방법에 대해 설명한다.\nIndex\nCA CA에서 인증서 생성하기 인증서 적용하기 Chain of Trust (plus) 인증서가 사용되는 프로세스 모식도 CA CA는 신뢰할 수 있는 기관에 의해 운영되는데, 주요 업무는 공개키 등록 시 본인 인증과 X.509와 같은 디지털 인증서 생성 및 발생 등이 있다.\nCA의 필요성 공개키와 비밀키만을 이용해 암호화는 수행하면 보안에 매우 취약해진다. [Picture 1] 에서 해커가 사용자 B에게 해커의 공개키를 사용하여 데이터를 보낼 경우 사용자 B는 사용자 A가 보낸 데이터라착각할 수 있다. 이와 같은 해커의 공격 방식을 MTM(Man in the Middle Attack)이라고 한다. 이와 같은 취약점을 해결하기 위해 CA(Certificate Authority) 라는 인증 노드를 사용하게 된다.\n[Picture 1] Man in Middle Attack\nPKI에서 CA가 사용되는 과정 사용자 A가 자신의 공개키를 CA에 등록한다. (본인 인증을 거친다) 사용자 B가 사용자 A의 공개키가 필요할 경우 CA에 가서 사용자 A의 공개키를 요청한다. CA는 사용자 A의 공개키를 암화화하여 사용자 B에게 전달한다. 사용자 B는 해당 공개키만을 사용자 A의 공개키라고 믿게 된다. [Picture 2] PKI에서 CA가 사용되는 과정\nCA 업체 유명한 CA들은 [Picture 3] 같다. CA의 인증서를 대리 구매해주는 서비스들이 외국에도, 한국에도 있지만 직접 CA에 가서 사는 것이 더 좋다. CA에 직접 가서 구매했을 때 QnA나 대응도 더 빠르고, 자세하며 나중에 인증서를 관리할 때에도 더 편했다.\n[Picture 3] 유명한 CA\nCA에서 인증서 생성하기 CA에서 인증서를 생성하기 위해서는 SAN과 CSR을 제출해야 한다. CA 업체에 따라서 추가 서류를 제출해야 할 수 있으니 발급 전에 확인해야 한다.\nSAN Subject Alternative Name 의 약자이다. Optional 이고, 선택한 인증서의 가격에 따라서 보장하는 SAN의 개수에도 차이가 있다. 하나의 인증서로 여러개의 FQDN (Fully Qualified Domain Name)를 보장할 수 있다. 하나의 IP로 향햐는 도메인이 여러개가 있을 때 자주 사용이 된다. SAN 예시\nwww.digicert.com knowledge.digicert.com www.thawte.com CSR Certificate signing request 의 약자이다. CA에서 certificate 발급받기 위해 보내는 메세지이다. 가장 많이 사용되는 포맷은 PKCS #10이다. CSR 을 만들기 전에 PrivateKey를 만드는데, 이 PrivateKey가 바로 PKI에서 사용되는 그 PrivateKey로 아무한테도 노출하면 안된다. [gogetssl] 처럼 인증서 중간 유통 업체들이 때때로 CSR과 PrivateKey를 사용자에게 주기도 한다. OpenSSL로 CSR 생성하기 openssl req -new -newkey rsa:2048 -sha256 -nodes -keyout server.key -out server.csr Private key을 생성한다. 생성한 Private key를 사용하여 CSR을 생성한다. CSR을 생성할 때 [Picture 4] 에 대한 정보를 입력해야 한다. [Picture 4] CSR 입력 사항\nCommon Name SAN이 나오고 나서부터 Common Name은 실제적인 효력 보다는 과거의 레거시 형태로 남아있다. 이번에도 CSR을 작성할 때 OV를 만들어야 하기 때문에 Common Name에 도메인을 쓰지 않고 회사 이름을 넣었다. Comman Name에 도메인을 넣는다면 인증서가 설치되는 서버의 이름과 정확하게 매치해야 한다. 만약 서브 도메인을 위해 인증서를 발급했을 경우에는 full 서브도메인을 정확하게 명시해줘야한다.\nCommon Name 예시\n도메인: mydomain.com 서브 도메인: www common name: www.domain.com Common Name vs SAN common name은 단 하나의 엔트리만 입력을 할 수 있다. wildcard 또는 non-wildcard 이라도 단 하나만 입력을 할수 있다는 것은 변함이 없다 SAN은 common name의 이런 제약을 없애기 위해 생겨났다. SAN이 있기 때문에 multi-name SSL 인증서를 만들 수 있게 되었다. SAN에는 여러가지 값을 넣을 수 있고, Common Name과 중복도 가능하다. SAN이 서버 네임이 일치하는 가 확인하기 위한 유일한 필수 레퍼런스가 되었다. 인증서 관련 커맨드 웹사이트에서 사용하고 있는 인증서 가져오기 echo | openssl s_client -servername google.com -connect google.com:443 |\\\\n sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' \u0026gt; certificate.crt 인증서 열어보기 openssl x509 -in certificate.crt -noout -text [파싱 결과 예시] Certificate: Data: Version: 3 (0x2) Serial Number: 59:43:1c:7c:0e:b1:5c:49:0a:01:4e:60:34:b8:2c:b2 Signature Algorithm: sha256WithRSAEncryption Issuer: C=US, O=Google Trust Services LLC, CN=GTS CA 1C3 Validity Not Before: Apr 25 08:31:18 2022 GMT Not After : Jul 18 08:31:17 2022 GMT Subject: CN=*.google.com Subject Public Key Info: Public Key Algorithm: id-ecPublicKey Public-Key: (256 bit) pub: 04:81:63🆎d3:29:a2:15:6c:ee:b7:43:66:55:c5: 88:6e:70:9b:4d:43:40:66:ea:a4:fc:c0:06:8b:4c: fd:60:23:5f:f7:a0:e4:3c:5a:af:7f:e5:36:63:88: 55:dd:e2:60:41:6c:a1:27:3d:48:fb:2e:6a:21:6d: 01:aa:2e:25:7e ASN1 OID: prime256v1 NIST CURVE: P-256 X509v3 extensions: X509v3 Key Usage: critical Digital Signature X509v3 Extended Key Usage: TLS Web Server Authentication X509v3 Basic Constraints: critical CA:FALSE X509v3 Subject Key Identifier: 8B:09:31:88:DD:30:A6:59:D3:86:E5:3D:EA:06:6D:F3:C0:25:96:D5 X509v3 Authority Key Identifier: keyid:8A:74:7F:AF:85:CD:EE:95:CD:3D:9C:D0:E2:46:14:F3:71:35:1D:27 Authority Information Access: OCSP - URI:http://ocsp.pki.goog/gts1c3 CA Issuers - URI:http://pki.goog/repo/certs/gts1c3.der X509v3 Subject Alternative Name: DNS:*.google.com, DNS:*.appengine.google.com, DNS:*.bdn.dev, DNS:*.cloud.google.com, DNS:*.crowdsource.google.com, DNS:*.datacompute.google.com, DNS:*.google.ca, DNS:*.google.cl, DNS:*.google.co.in, DNS:*.google.co.jp, DNS:*.google.co.uk, DNS:*.google.com.ar, DNS:*.google.com.au, DNS:*.google.com.br, DNS:*.google.com.co, DNS:*.google.com.mx, DNS:*.google.com.tr, DNS:*.google.com.vn, DNS:*.google.de, DNS:*.google.es, DNS:*.google.fr, DNS:*.google.hu, DNS:*.google.it, DNS:*.google.nl, DNS:*.google.pl, DNS:*.google.pt, DNS:*.googleadapis.com, DNS:*.googleapis.cn, DNS:*.googlevideo.com, DNS:*.gstatic.cn, DNS:*.gstatic-cn.com, DNS:googlecnapps.cn, DNS:*.googlecnapps.cn, DNS:googleapps-cn.com, DNS:*.googleapps-cn.com, DNS:gkecnapps.cn, DNS:*.gkecnapps.cn, DNS:googledownloads.cn, DNS:*.googledownloads.cn, DNS:recaptcha.net.cn, DNS:*.recaptcha.net.cn, DNS:recaptcha-cn.net, DNS:*.recaptcha-cn.net, DNS:widevine.cn, DNS:*.widevine.cn, DNS:ampproject.org.cn, DNS:*.ampproject.org.cn, DNS:ampproject.net.cn, DNS:*.ampproject.net.cn, DNS:google-analytics-cn.com, DNS:*.google-analytics-cn.com, DNS:googleadservices-cn.com, DNS:*.googleadservices-cn.com, DNS:googlevads-cn.com, DNS:*.googlevads-cn.com, DNS:googleapis-cn.com, DNS:*.googleapis-cn.com, DNS:googleoptimize-cn.com, DNS:*.googleoptimize-cn.com, DNS:doubleclick-cn.net, DNS:*.doubleclick-cn.net, DNS:*.fls.doubleclick-cn.net, DNS:*.g.doubleclick-cn.net, DNS:doubleclick.cn, DNS:*.doubleclick.cn, DNS:*.fls.doubleclick.cn, DNS:*.g.doubleclick.cn, DNS:dartsearch-cn.net, DNS:*.dartsearch-cn.net, DNS:googletraveladservices-cn.com, DNS:*.googletraveladservices-cn.com, DNS:googletagservices-cn.com, DNS:*.googletagservices-cn.com, DNS:googletagmanager-cn.com, DNS:*.googletagmanager-cn.com, DNS:googlesyndication-cn.com, DNS:*.googlesyndication-cn.com, DNS:*.safeframe.googlesyndication-cn.com, DNS:app-measurement-cn.com, DNS:*.app-measurement-cn.com, DNS:gvt1-cn.com, DNS:*.gvt1-cn.com, DNS:gvt2-cn.com, DNS:*.gvt2-cn.com, DNS:2mdn-cn.net, DNS:*.2mdn-cn.net, DNS:googleflights-cn.net, DNS:*.googleflights-cn.net, DNS:admob-cn.com, DNS:*.admob-cn.com, DNS:*.gstatic.com, DNS:*.metric.gstatic.com, DNS:*.gvt1.com, DNS:*.gcpcdn.gvt1.com, DNS:*.gvt2.com, DNS:*.gcp.gvt2.com, DNS:*.url.google.com, DNS:*.youtube-nocookie.com, DNS:*.ytimg.com, DNS:android.com, DNS:*.android.com, DNS:*.flash.android.com, DNS:g.cn, DNS:*.g.cn, DNS:g.co, DNS:*.g.co, DNS:goo.gl, DNS:www.goo.gl, DNS:google-analytics.com, DNS:*.google-analytics.com, DNS:google.com, DNS:googlecommerce.com, DNS:*.googlecommerce.com, DNS:ggpht.cn, DNS:*.ggpht.cn, DNS:urchin.com, DNS:*.urchin.com, DNS:youtu.be, DNS:youtube.com, DNS:*.youtube.com, DNS:youtubeeducation.com, DNS:*.youtubeeducation.com, DNS:youtubekids.com, DNS:*.youtubekids.com, DNS:yt.be, DNS:*.yt.be, DNS:android.clients.google.com, DNS:developer.android.google.cn, DNS:developers.android.google.cn, DNS:source.android.google.cn X509v3 Certificate Policies: Policy: 2.23.140.1.2.1 Policy: 1.3.6.1.4.1.11129.2.5.3 X509v3 CRL Distribution Points: Full Name: URI:http://crls.pki.goog/gts1c3/QOvJ0N1sT2A.crl 1.3.6.1.4.1.11129.2.4.2: ......v.)y...99!.Vs.c.w..W}.` ..M]\u0026amp;\\%]......`........G0E.!......Y.Z...Z.s#...Al...\u0026amp;......Wi. m.-a..._^,...#....D.tZ.j..W.g....w...^.h.O.l..._N\u0026gt;Z.....j^.;.. D\\*s....`..!.....H0F.!..6:.?...f..m.}%.r..........E.....!..U....G...%.$D.mG.B.. Signature Algorithm: sha256WithRSAEncryption 5c:2b:62:ec:f6:ee:92:0c:28:98:92:af:35:f0:78:5b:75:f2: a2:c5:e9:56:04:da:31:ed:0c:92:16:3a:14:47:f9:60:7d:e4: 36:33:82:13:68:54:37:47:81:f8:b6:0e:66:a7:87:c4:f5:82: ca:58:62:a2:15:63:16:28:5b:8e:bc:e7:18:af:97:a2:f4:92: 92:e3:2f:69:df:ba:7a:80:92:20:14:22:4f:3d:26:69:c6:f8: 90:d1:2c:36:57:0a:5c:20:00:86:d2:bd:52:db:19:39:46:12: b0:65:1d:16:3d:f1:58:4b:d6:19:c0:4b:0d:eb:ad:0b:b9:1c: 03:ad:cb:d1:04:33:a2:2c:b8:33:f6:01:7c:71:7f:e8:8a:32: c1:74:9a:11:f7🆎b9:ff:f8:89:99:f3:f9:50:7b:31:c7:fa: fc:71:d1:c6:f2:b4:d2:82:93:84:ae:d8:eb:55:41:d4:de:9d: 7f:47:44:05:4a:fb:a7:09:b2:89:99:a7:7f:64:13:52:be:73: ee:00:b9:1c:ad:e1:44:48:41:a4:77:55:8d:0a:c8:b0:bb:69: fe:9a:84:a5:cd:2d:a9:61:3b:60:92:e4:43:d6:2b:79:d6:5a: 0d:db:f7:7f:7a:fc:7d:c3:59:e3:7d:d7:47:78:c2:b2:7d:6d: f2:7a:75:49 간단하게 인증서 조회를 하기 위해서는 online parser를 사용할 수 있다. [Online Parser] 파싱의 결과로 나온 field에 대한 설명은 [LeeLee- Digital Certificate] 포스트 에서 더 자세하게 확인할 수 있다.\n인증서 적용하기 CA bundle CA에서 인증서를 발급받으면 end-entity (내 application)의 인증서만 오지 않는다. Root CA의 인증서와 Intermediate 인증서가 함께 오는데 이를 CA bundle이라고 한다. CA bundle은 웹 브라우저 등의 클라이언트와 인증서의 호완성을 높히기 위해서 사용이 된다.\nCA bundle 예시\nRoot CA 인증서 + Intermediate 인증서 + end-entity 인증서 = Certificate Chain [Picture 5] CA bundle\nCA bundle은 *.ca-bundle 확장자의 zip 파일이나 root, intermediate 개별로 주어진다. CA bundle은 클라이언트에게 순차적으로 제공이 되어야 하기 때문에 대게는 CA에서 이미 하나의 bundle을 만들어서 제공해준다. 만약 개별로 주어졌을 경우에는 하나의 ca-bundle로 합쳐야 한다\nCA bundle 합치기 예시\nAddTrustExternalCARoot.crt –\u0026gt; Root CA Certificate COMODORSAAddTrustCA.crt –\u0026gt; Intermediate CA Certificate 1 COMODORSADomainValidationSecureServerCA.crt –\u0026gt; Intermediate CA Certificate 2 yourDomain.crt –\u0026gt; Your SSL Certificate cat ComodoRSADomainValidationSecureServerCA.crt ComodoRSAAddTrustCA.crt AddTrustExternalCARoot.crt \u0026gt; yourDomain.ca-bundle Google CA Bundle 예시\n브라우저의 브라우징 창에 🔒 모양을 누르면 해당 도메인에 대한 인증서의 종류, 상태 등을 볼 수 있는데 google.com의 인증서를 열어봤을 때에도 아래처럼 인증서가 계층을 이루고 있다.\nend-entity 인증서: *.google.com Intermediate 인증서: GTS CA 1C3 Root 인증서: GTS Root R1 [Picture 6] End Entity Certificate\n[Picture 7] Intermediate Certificate\n[Picture 8] Root Certificate\nApply CA Bundle CA bundle을 서버 호스트 어디엔가 다운로드해두었다면 해당 도메인이 등록되어있는 Nginx 등의 웹서버에 CA Bundle가 있는 path를 적어주면 된다. 그럼 알아서 클라이언트에게 CA Bundle을 한꺼번에 넘겨준다. 클라이언트는 이 Bundle을 통해서 end-entity가 믿을 수 있는지 없는지 여부를 결정한다. 이와 같은 과정을 Chain of Trust라고 한다.\n인증서를 서버에 다운로드 하는 것을 ‘installed’ 한다고 표현하는데 실제로는 인증서를 서버에 설치한다기 보다는 특정 디렉터리에 넣어둔다.\nLet’s encrypt 를 인증서로 사용했을 때 Nginx의 configuration 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 server { root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name www.test.me test.me; location / { try_files $uri $uri/ =404; } listen [::]:443 ssl http2; # managed by Certbot listen 443 ssl http2; # managed by Certbot ssl_certificate /etc/letsencrypt/live/test.me/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/test.me/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } 14번 줄의 의 fullchain.pem이 하나로 압축이 된 CA bundle이다. Let’s encrypt에서는 처음부터 하나로 압축된 ca-bundle을 pem 형식으로 제공해준다.\nChain of Trust CA가 서명한 인증서의 내부 구조 CA가 서명을 end-entity의 인증서에 서명을 하게 되면 end-entity의 인증서에는 아래와 같은 정보가 추가되어 발급된다.\n누가 서명을 했는지 (Issuer name) Issuer의 Digital Signature (Issuer의 Private key로 서명) end-entity (Subject)의 public key [Picture 9] End Entity Certificate 내부 구조\nChain of Trust 과정 Chain of Trust는 브라우저가 신뢰할 수 있는 CA가 Issuer로 있는 인증서를 찾기 까지 모든 layer의 인증서를 탐색하는 과정이라고 생각하면 된다. 다른 말로 신뢰할 수 있는 CA가 발급한 인증서를 증명하는 과정이다. 참고로 브라우저에 Root CA의 인증서를 보내도 대부분은 그 인증서를 쓰지 않고, 브라우저에 이미 자체적으로 저장이 되어있는 Root CA 인증서를 사용한다.\nChain 시나리오 End-entity의 인증서 제출 End-entity는 브라우저가 신뢰할 수 있는 CA가 아니다. End-entity의 Issuer를 확인한다. Intermediate CA가 Issuer로 되어있다. Intermediate CA는 브라우저가 신뢰할 수 있는 CA가 아니다. intermediate CA의 Issuer를 확인한다. Root CA가 Issuer로 되어있다. Root CA는 브라우저가 신뢰할 수 있는 CA다. Root CA의 digital signature를 브라우저가 이미 가지고 있는 Root CA의 public key로 verify한다. Root CA digital signature verify 완료. Root CA → Intermediate CA → End-entity 모두 chain of trust를 통해서 믿을 수 있는 인증서가 된다. [Picture 10] Chain of Trust 과정\nChain 계층 [Picture 11] Chain 계층\nRoot Certificate AKA Trust Anchor 최상단인 Root는 보증해 줄 곳이 없기 때문에 Root CA는 self-signed을 한다. OS, 서드파티 웹 브라우저, 클라이언트 어플리케이션은 Root CA의 인증서를 사전에 설치해둔다. clinet는 chain of trust를 통해서 end-entity가 Root 에 인증이 되었는지 식별할 수 있다. Root가 end-entity에 직접 서명하는 일은 거의 없고, 중간에 하나 또는 여러 개의 Intermediate CA가 서명을 한다. Root의 Private key가 변경이 되었다면 해당 Private key로 발급받은 모든 인증서를 재발급 해야 한다. Intermediate Certificate 거의 모든 SSL 인증서 chain에는 최소 하나의 Intermediate CA가 들어가 있다. Intermediate CA는 Root CA의 신뢰성(trustworthy)의 확장에 필수적인 연결점이고, Root CA와 end-entity에 추가적인 보안 레벨이 된다. End-entity Certificate End-entity의 인증서는 보안, 확장성, CA compliance 등을 제공하지만, 인증서를 발급받은 대상 (subject)의 신뢰성을 보장하지는 못한다. End-entity는 크리티컬한 정보를 CSR에 담아 인증서를 발급해주는 CA(issuer)에게 제출하고, CA가 판단하기에 제출된 정보가 믿을 수 있다면 CA의 Private key로 서명을 한 인증서를 발급해준다. 이 인증서가 verified 또는 signed 되어있지 않다면 SSL connection은 실패한다. (plus)인증서가 사용되는 프로세스 모식도 브라우저와 서버의 request - response 과정 모식도\n[Picture 11] request - response 과정 모식도\n브라우저가 youtube.com 을 요청한다. youtube가 인증서 번들을 브라우저에 제출한다. 브라우저는 자신의 CA public key 리스트로 서버가 제출한 인증서가 정말로 신뢰할 수 있는 CA에 의해 서명되었는지 확인한다. Intermediate CA는 지정된 Root CA가 아니기 때문에 브라우저의 입장에서는 믿을 수 없는 CA다. 제출된 인증서 번들을 타고 올라가서 Root CA까지 간다. 신뢰하기로 한 인증서에 명시되어있는 domain name이나 ip가 맞다면, 서버의 public key를 사용하여 대칭키를 생성하여 서버와 공유한다. 이 대칭키로 connection의 모든 트래픽을 암호화한다. 대칭키를 사용하는 것이 비대칭키를 사용하여 모든 커뮤니케이션을 암호화하는 것보다 효율적이기 때문에 대칭키르르 사용한다. 복호화는 private key를 가지고 있는 서버만 가능하다. CA-signed 인증서 발급 과정 모식도\n[Picture 12] CA-signed 인증서 발급 과정 모식도\nSelf-signed 인증서 발급 과정 모식도\n[Picture 13] Self-signed 인증서 발급 과정 모식도\n","date":"2022-08-27","permalink":"https://leeleelee3264.github.io/post/2022-08-27-digital-certificate-part-final/","tags":["Infra"],"title":"Digital certificate 적용하기"},{"content":"\noauth2를 사용하고 있는 Myinfo API 를 사용하는 connector client를 Python/Django로 구현한다.\n[github]\n[api document]\n[quick start]\nIndex\nMyinfo란? 프로젝트 목표 프로젝트 구현 프로젝트 회고 Myinfo란? 싱가폴 Mydata 서비스 정부가 주도한 Mydata 서비스가 몇 개의 나라에 있다고 하는데, 싱가폴 정부의 Singpass는 그 중에서도 모범사례로 뽑힌다고 한다. Singpass는 싱가포르의 15세 이상의 인구 중 97% 가 쓰고 있는 아주 활발한 서비스이다.\nSingpass에 있는 여러가지 서비스 중 Myinfo는 Person Data를 제공하는 서비스로, 한국의 카카오나 네이버 아이디 처럼 ouath2 로그인과 회원가입을 할 수 있다. [Picture 1] 에서 singpass에 대해서 조금 더 자세히 살펴볼 수 있다.\n[Picture 1] Introduce Singpass\nMyinfo oauth2 Myinfo는 [Picture 2] 와 같은 oauth2 구조를 가진다.\n[Picture 2] Myinfo oauth2 구조\nResource Owner Myinfo 사용자 Application 내가 구현하는 connector로, Myinfo 사용자의 데이터를 사용하는 주체 Identify Providers / Service Authorization Platform 인증서버 사용자의 인증정보와 권한 정보를 소유한 서버 Singpass 로그인 페이지 제공 Resource Server 사용자 데이터를 소유한 서버 인증 서버에 로그인 성공 후 접근 Myinfo Resource API 권한 인증 요청 [authorise api] GET /v3/authorise Singpass 로그인 페이지를 불러온다. 로그인 후 Singpass에서 사용자의 데이터를 불러오는 것에 대한 동의를 진행한다. 사용자가 동의했을 경우 authcode를 return 한다. Token 요청 [token api] POST /v3/token authocode를 사용하여 token을 요청한다. PKI를 사용하여 인증을 진행한다. 인증이 완료되면 token을 return 한다. 사용자 정보 요청 [person api] GET /v3/person/{sub} token 속의 access token을 사용하여 사용자 정보를 요청한다. 사용자 정보를 return 한다. 프로젝트 목표 Singpass가 제공하는 [Java]와 [node.js] 버전의 client connector 처럼 이번에 프로젝트로 python 버전의 connector를 만들었다. 아예 하나의 REST API 형태로 제공을 하기 위해 프레임워크로 Django를 선택했다.\n프로젝트 목표 프로젝트를 진행하면서 이루고자 한 목표는 아래와 같다. 대부분의 토이 프로젝트가 제대로 정리가 되어있지 않거나 코드가 엉망으로 짜여질 때가 많아서 이번에는 처음부터 확실하게 목표를 설정했다.\nCode Quality\nDDD 아키텍처로 서버를 구현한다. 최소 2회의 리팩토링을 진행한다. python lint(flake8, pylint, mypy)를 사용하여 최대한 python style을 고수한다. Pipenv를 사용해서 python 패키지를 관리한다. Documentation\nGithub README를 작성한다. API document를 작성한다. Project에 대한 블로그 포스팅을 작성한다. Dev Stack stack info Backend Language Python Backend Framework Django Code Architecture Domain Driven Desgin Python Package Managment Pipenv API Security PKI Version Control Github API Document GitBook 프로젝트 구현 Make Request Myinfo oauth2 구조를 반영하여, connector 서버의 호출 flow를 [Picture 3] 같이 설계했다.\n[Picture 3] connector 서버 호출 flow\nStep 1: Get myinfo login url Request GET /users/me/external/myinfo-redirect-login\ncurl -i -H 'Accept: application/json' \u0026lt;http://localhost:3001/user/me/external/myinfo-redirect-login\u0026gt; Response { \u0026quot;message\u0026quot;: \u0026quot;OK\u0026quot;, \u0026quot;data\u0026quot;: { \u0026quot;url\u0026quot;: \u0026quot;https://test.api.myinfo.gov.sg/com/v3/authorise?client_id=STG2-MYINFO-SELF-TEST\u0026amp;attributes=name,dob,birthcountry,nationality,uinfin,sex,regadd\u0026amp;state=eb03c000-00a3-4708-ab30-926306bfc4a8\u0026amp;redirect_uri=http://localhost:3001/callback\u0026amp;purpose=python-myinfo-connector\u0026quot;, \u0026quot;state\u0026quot;: \u0026quot;eb03c000-00a3-4708-ab30-926306bfc4a8\u0026quot; } } Step 2: Browse myinfo login url Request curl \u0026lt;https://test.api.myinfo.gov.sg/com/v3/authorise?client_id=STG2-MYINFO-SELF-TEST\u0026amp;attributes=name,dob,birthcountry,nationality,uinfin,sex,regadd\u0026amp;state=eb03c000-00a3-4708-ab30-926306bfc4a8\u0026amp;redirect_uri=http://localhost:3001/callback\u0026amp;purpose=python-myinfo-connector\u0026gt; Response [Picture 4] Myinfo Login Page\nStep 3: Login and check agree terms Login Check Login page in [Picture 5]\nAgree Terms [Picture 5] Myinfo Terms Agreement Page\nStep 4: Callback API get called by Myinfo Myinfo에서 Request를 하는 Step이다.\n로그인을 하고 terms에 동의를 하면 Myinfo에서 connector client의 callback API를 호출해 authcode를 넘겨준다.\nRequest GET /callback?{code}\ncurl \u0026lt;http://localhost:3001/callback?code=8932a98da8720a10e356bc76475d76c4c628aa7f\u0026amp;state=e2ad339a-337f-45ec-98fa-1672160cf463\u0026gt; Response [Picture 6] Callback Response Page\nFinal Step: Get Person data 자동화된 Step이다.\nCallback API의 응답인 callback 페이지는 자동으로 connector client의 person data API를 호출하도록 했다. 해당 API가 Myinfo에서 사용자 정보를 가져오는 마지막 단계이다.\nRequest GET /users/me/external/myinfo\ncurl -i -H 'Accept: application/json' \u0026lt;http://localhost:3001/user/me/external/myinfo\u0026gt; Response { \u0026quot;message\u0026quot;: \u0026quot;OK\u0026quot;, \u0026quot;sodata\u0026quot;: { \u0026quot;regadd\u0026quot;: { \u0026quot;country\u0026quot;: { \u0026quot;code\u0026quot;: \u0026quot;SG\u0026quot;, \u0026quot;desc\u0026quot;: \u0026quot;SINGAPORE\u0026quot; }, \u0026quot;unit\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;10\u0026quot; }, \u0026quot;street\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;ANCHORVALE DRIVE\u0026quot; }, \u0026quot;lastupdated\u0026quot;: \u0026quot;2022-07-14\u0026quot;, \u0026quot;block\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;319\u0026quot; }, \u0026quot;source\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;postal\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;542319\u0026quot; }, \u0026quot;classification\u0026quot;: \u0026quot;C\u0026quot;, \u0026quot;floor\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;38\u0026quot; }, \u0026quot;type\u0026quot;: \u0026quot;SG\u0026quot;, \u0026quot;building\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;\u0026quot; } }, \u0026quot;dob\u0026quot;: \u0026quot;1988-10-06\u0026quot;, \u0026quot;sex\u0026quot;: \u0026quot;M\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;ANDY LAU\u0026quot;, \u0026quot;birthcountry\u0026quot;: \u0026quot;SG\u0026quot;, \u0026quot;nationality\u0026quot;: \u0026quot;SG\u0026quot;, \u0026quot;uinfin\u0026quot;: \u0026quot;S6005048A\u0026quot; } } PKI Digital Signature Myinfo는 PKI Digital Signature를 필요로 한다. 해당 문서에서는 python에서 구현을 할 때 PKI를 사용하는 방법만을 다루기 때문에 PKI에 대한 더 자세한 설명은 링크로 첨부하겠다. [LeeLee- Digital Certificate]\npython 패키지로는 *jwcrypto*와 Crypto를 사용했다.\nPKI 시나리오 connector client private key\n[myinfo token api]를 호출할 때 [myinfo person api]를 호출 할 때 [myinfo person api] 응답 decrypt 할 때 myinfo에서 connector client의 public key로 응답을 암호화 했기 때문 myinfo public key\nmyinfo token api 응답 verify 할 때 myinfo에서 myinfo의 private key로 응답을 암호화 했기 때문 myinfo person api 응답 verify 할 때 myinfo에서 myinfo의 private key로 응답을 암호화 했기 때문 public, privateKey 불러오기 1 2 3 4 5 6 7 8 9 10 11 from jwcrypto import jwk PrivateKey = jwk.JWK PublicKey = jwk.JWK def _get_key(self, key: str) -\u0026gt; Union[PrivateKey, PublicKey]: encode_key = key.encode(\u0026#39;utf-8\u0026#39;) key_dict = jwk.JWK.from_pem(encode_key) return key_dict connector client private key로 서명하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import base64 from Crypto.Hash import SHA256 from Crypto.PublicKey import RSA from Crypto.Signature import PKCS1_v1_5 Signature = str def _sign_on_raw_header( self, base_string: str, private_key: str, ) -\u0026gt; Signature: digest = SHA256.new() digest.update( base_string.encode(\u0026#39;utf-8\u0026#39;), ) pk = RSA.importKey(private_key) signer = PKCS1_v1_5.new(pk) signature = str(base64.b64encode(signer.sign(digest)), \u0026#39;utf-8\u0026#39;) return signature connector client private key로 응답 decrypt 하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import json from jwcrypto import ( jwe, jwk, ) PrivateKey = jwk.JWK def _decrypt( self, encrypted_payload: str, key: PrivateKey, ) -\u0026gt; DecryptedPersonData: params = self._get_decrypt_params(encrypted_payload) encryption = jwe.JWE() encryption.deserialize(params, key) data = encryption.plaintext data_str = json.loads(data) return data_str myinfo public key로 응답 verify 하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import json from jwcrypto import jwk PublicKey = jwk.JWK DecodedPersonData = dict def _decode( self, encoded_payload: str, key: PublicKey, ) -\u0026gt; DecodedPersonData: token = jwt.JWT() token.deserialize(jwt=encoded_payload, key=key) data = token.claims data_dict = json.loads(data) person = DecodedPersonData(**data_dict) return person 프로젝트 회고 문서화 정해둔 목표를 잘 이행한 기분이 들어서 뿌듯했다. 또한 항상 미흡했던 문서화를 꼼꼼하게 해 둔 거 같아 만족스럽다. 하지만 문서화를 하는 과정에서 어떻게 내가 말하고자 하는 바를 더 깔끔하게 글로 옮길 수 있을까 고민을 많이 했고, 아직도 부족한 부분이 많이 보인다. 리팩토링 코드 또한 2번 리팩토링을 진행했지만 포스팅을 위해서 다시 코드를 보니 또 리팩토링 해야겠다는 생각이 든다. 프로젝트를 할 때 1,2번의 리팩토링을 하고 프로젝트가 끝나고 2~3달 지나서 리팩토링을 1 번 진행하면 좋을 거 같다. Boilerplate 어떤 프로젝트를 하더라도 프레임워크 setting을 하는데 초기 시간을 많이 소요하는데, 앞으로 Django로 계속 프로젝트를 진행할 예정이라면 pre-setting이 어느 정도 되어있는 Django Boilerplate 를 만들어야겠다.\n","date":"2022-07-23","permalink":"https://leeleelee3264.github.io/post/2022-07-23-project-myinfo-connector-python/","tags":["Project"],"title":"Python으로 Myinfo oauth2 client connector 구현하기"},{"content":"\n간단한 프로파일링을 할 수 있는 profiler를 Python decorator로 구현한다.\nIndex\nprofiler 구현 계기 profiler 구현 개선해야 하는 부분 profiler 구현 계기 Django 환경에서 unittest를 하며 간단하게 퍼포먼스를 측정하고 싶었다. 아주 간단하게 프로파일링을 하면 되기 때문에 Middleware 같은 것은 만들지 않았다. 대신에 Python의 decorator로 만들었다. 앞으로 더 심화되고 유익한 정보를 포함하고 있는 Profiler를 decorator 형식으로 만들면 유용할 것 같다.\n구현한 profiler\n메모리 사용량을 보기 위한 ram_profiler 함수에서 호출된 쿼리와 쿼리 실행시간을 보기 위한 query_profiler 함수 실행시간 을 보기 위한 elapsed_timer profiler 구현 ram_profiler 이 프로파일러를 구현하다가 알게 된 사실인데 Python에서 메모리나 CPU 사용량을 보려면 psutill builtin 패키지를 사용하는 경우가 많았다.\ndecorator는 함수 호출 전과 후의 메모리 사용량을 가져와, 함수가 호출이 되면서 얼추 어느 정도의 메모리를 사용했는지 비교할 수 있도록 한다.\nram_profiler 구현 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def ram_profiler(fn): \u0026#34;\u0026#34;\u0026#34; 퍼포먼스 체크를 위한 메모리 프로파일러 메모리 사용량을 측정할 함수 위에 @ram_profiler 를 추가해주시면 됩니다. 체크하는 메모리는 아래와 같습니다. 1) 그냥 현재 memory usage 정보를 그대로 가져오는 경우 2) 현재 process id를 통해 해당 프로세스의 memory usage를 정확하게 비교하는 경우 ex) @ram_profiler def pre_allot_offering(offering: Offering): \u0026#34;\u0026#34;\u0026#34; def inner(*args, **kwargs): print(\u0026#39;\\n\u0026#39;) print(\u0026#34;===== memory usage check =====\u0026#34;) memory_usage_dict = dict(psutil.virtual_memory()._asdict()) memory_usage_percent = memory_usage_dict[\u0026#39;percent\u0026#39;] print(f\u0026#34;BEFORE CODE :: memory_usage_percent: {memory_usage_percent}%\u0026#34;) pid = os.getpid() current_process = psutil.Process(pid) current_process_memory_usage_as_kb = current_process.memory_info()[0] / 2. ** 20 print(f\u0026#34;BEFORE CODE :: Current memory KB : {current_process_memory_usage_as_kb: 9.3f} KB\u0026#34;) target_func = fn(*args, **kwargs) print(\u0026#34;==\u0026#34; * 20) print(f\u0026#34;== {fn.__name__} memory usage check ==\u0026#34;) memory_usage_dict = dict(psutil.virtual_memory()._asdict()) memory_usage_percent = memory_usage_dict[\u0026#39;percent\u0026#39;] print(f\u0026#34;AFTER CODE :: memory_usage_percent: {memory_usage_percent}%\u0026#34;) pid = os.getpid() current_process = psutil.Process(pid) current_process_memory_usage_as_kb = current_process.memory_info()[0] / 2. ** 20 print(f\u0026#34;AFTER CODE :: Current memory KB : {current_process_memory_usage_as_kb: 9.3f} KB\u0026#34;) print(\u0026#39;\\n\u0026#39;) return target_func return inner ram_profiler 결과 ===== memory usage check ===== BEFORE CODE :: memory_usage_percent: 79.7% BEFORE CODE :: Current memory KB : 197.250 KB ======================================== == pre_allot_offering memory usage check == AFTER CODE :: memory_usage_percent: 79.7% AFTER CODE :: Current memory KB : 197.312 KB query_profiler decorator는 쿼리를 관리하는 context를 임포트 해와서 타겟 함수를 실행하면서 호출되었던 쿼리들을 캡처해두었다가 함수가 끝이 나면 보여준다. ORM에서 실제로 어떤 쿼리가 실행되는지 봐야 할 때, 조건문에 따라 쿼리가 달라질 때, N + 1 쿼리를 잡아 낼 때 사용하기 좋다.\nquery_profiler 구현 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def query_profiler(fn): \u0026#34;\u0026#34;\u0026#34; 호출이 된 query를 확인하기 위한 프로파일러 호출 된 query를 확인할 함수 위헤 @query_profiler 를 추가해주시면 됩니다. ex) @query_profiler def pre_allot_offering(offering: Offering): \u0026#34;\u0026#34;\u0026#34; def inner(*args, **kwargs): print(\u0026#39;\\n\u0026#39;) print(f\u0026#34;===== {fn.__name__} called query check =====\u0026#34;) with CaptureQueriesContext(connection) as context: target_func = fn(*args, **kwargs) for index, query in enumerate(context.captured_queries): sql = query.get(\u0026#39;sql\u0026#39;) time = query.get(\u0026#39;time\u0026#39;) print(f\u0026#39;CALLED QUERY :: [{index}]\u0026#39;) print(f\u0026#39;CALLED QUERY :: query: {sql}\u0026#39;) print(f\u0026#39;CALLED QUERY :: executed time: {time}\u0026#39;) print(\u0026#34;=====\u0026#34;) return target_func return inner query_profiler 결과 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ===== pre_allot_offering called query check ===== CALLED QUERY :: [0] CALLED QUERY :: query: SAVEPOINT `s4377609600_x5` CALLED QUERY :: executed time: 0.001 ===== CALLED QUERY :: [1] CALLED QUERY :: query: SELECT `offering_subscription`.`id` # 실제 쿼리는 블라인드 CALLED QUERY :: executed time: 0.00 ===== CALLED QUERY :: [2] CALLED QUERY :: query: UPDATE `offering_subscription` SET # 실제 쿼리는 블라인드 CALLED QUERY :: executed time: 0.003 ===== CALLED QUERY :: [3] CALLED QUERY :: query: SELECT `offering_subscription`.`id`, # 실제 쿼리는 블라인드 ===== CALLED QUERY :: [4] CALLED QUERY :: query: SELECT `offering_subscription`.`id`, # 실제 쿼리는 블라인드 CALLED QUERY :: executed time: 0.002 ===== CALLED QUERY :: [5] CALLED QUERY :: query: UPDATE `offering_subscription` SET # 실제 쿼리는 블라인드 CALLED QUERY :: executed time: 0.002 ===== CALLED QUERY :: [6] CALLED QUERY :: query: RELEASE SAVEPOINT `s4377609600_x5` CALLED QUERY :: executed time: 0.001 ===== elapsed_timer decorator는 함수의 시작시간과 끝나는 시간을 측정하여 함수 실행시간이 어느정도인지를 계산한다.\nelapsed_timer 구현 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def elapsed_timer(fn): \u0026#34;\u0026#34;\u0026#34; 퍼포먼스 체크를 위한 실행 시간 측정 타이머 실행 시간을 측정할 함수 위에 @elapsed_timer 를 추가해주시면 됩니다. 퍼포먼스 테스트가 끝나면 지워주시길 바랍니다. ex) @elapsed_timer def pre_allot_offering(offering: Offering): \u0026#34;\u0026#34;\u0026#34; def inner(*args, **kwargs): print(\u0026#39;\\n\u0026#39;) print(f\u0026#34;===== {fn.__name__} elapsed time check =====\u0026#34;) start = perf_counter() target_func = fn(*args, **kwargs) end = perf_counter() print(f\u0026#39;ELAPSED :: total: start: {start} sec - end: {end} sec\u0026#39;) duration = end - start print(f\u0026#39;ELAPSED :: duration: {duration} sec\u0026#39;) print(f\u0026#39;ELAPSED :: duration in minutes : {str(timedelta(seconds=duration))} mins\u0026#39;) print(\u0026#39;\\n\u0026#39;) return target_func return inner elapsed_timer 결과 1 2 3 4 ===== pre_allot_offering elapsd time check ===== ELAPSED :: total: start: 8.705878 sec - end: 8.72449375 sec ELAPSED :: duration: 0.018615750000000375 sec ELAPSED :: duration in minutes : 0:00:00.018616 mins (builtin) @profiler 메모리를 프로파일링하는 것에 한정한다면 Python에서 builtin으로 제공하는 memory_profiler 라는 것이 있다. 패키지 안의 @profiler 데코레이터를 사용하면 함수 안에서 코드가 실행이 될 때 한 줄 한 줄 얼마의 메모리를 사용했는지를 볼 수 있다.\nORM을 포함하고 있는 코드에도 사용을 해보려 했는데 recursive 하게 동작을 하다가 스택이 터져서 사용을 할 수 없었다. 함수가 한 줄 씩 호출되면서 메모리 사용량을 보기에는 정말 좋은 데코레이터 처럼 보이는데 꼭 다음에 써보도록 해야겠다.\n@profiler 사용 예시 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from memory_profiler import profile @profile def main_func(): import random arr1 = [random.randint(1,10) for i in range(100000)] arr2 = [random.randint(1,10) for i in range(100000)] arr3 = [arr1[i]+arr2[i] for i in range(100000)] del arr1 del arr2 tot = sum(arr3) del arr3 print(tot) if __name__ == \u0026#34;__main__\u0026#34;: main_func() @profiler 결과 예시 1 2 3 4 5 6 7 8 9 10 11 12 13 Line # Mem usage Increment Line Contents ================================================ 3 37.0 MiB 37.0 MiB @profile 4 def main_func(): 5 37.0 MiB 0.0 MiB import random 6 37.6 MiB 0.3 MiB arr1 = [random.randint(1,10) for i in range(100000)] 7 38.4 MiB 0.3 MiB arr2 = [random.randint(1,10) for i in range(100000)] 8 39.9 MiB 0.5 MiB arr3 = [arr1[i]+arr2[i] for i in range(100000)] 9 39.9 MiB 0.0 MiB del arr1 10 38.0 MiB 0.0 MiB del arr2 11 38.0 MiB 0.0 MiB tot = sum(arr3) 12 37.2 MiB 0.0 MiB del arr3 13 37.2 MiB 0.0 MiB print(tot) 개선해야 하는 부분 Python의 Decorator는 함수의 시작 - 끝 부분에 추가 action을 할 수 있게 해주는 Wrapper이다. 함수 중간중간에 프로파일링을 해야 한다면 다른 방법으로 접근을 해야 할 것 같다.\n","date":"2022-06-29","permalink":"https://leeleelee3264.github.io/post/2022-06-30-python-profiler-decorator/","tags":["Backend"],"title":"Python decorator로 간단한 profiler 구현하기"},{"content":"\nPKI의 certificate에 대해서 다룬다.\nIndex\n인증서에 대해 잘못 알고 있던 점들 인증서의 종류 인증서와 관련된 개념 인증서에 대해 잘못 알고 있던 점들 인증서의 종류 적절하지 않은 인증서 분류 web에서 HTTPS 통신을 하기 위해 사용하는 web secure용 SSL 인증서 digital signature(디지털 서명) 를 하기 위한 code signing 인증서 디지털 서명을 해야 했기 때문에 code signing 인증서를 발급받으려 했다. 하지만 SSL 인증서도 디지털 서명을 할 수 있었고, 목표인 server to server 커뮤니케이션에서 사용하는 신원 보장용 디지털 서명을 하기 위해서는 SSL 인증서를 발급해야 했다.\n[Picture 1] 적절하지 않은 인증서 분류\n적절한 인증서 분류 SSL 인증서는 웹사이트, 정확히 말하면 브라우저에 한정해서 사용한다고 생각했는데 이는 너무 한정적인 생각이었다. SSL 인증서는 client와 server가 (browser to server / server to server) 데이터를 주고 받을 때 암호화를 하기 위해 쓰이기 때문에 브라우저에 한정적이지 않다.\n결국 인증서는 [Picture 2] 처럼 분류를 해야 한다.\n[Picture 2] 적절한 인증서 분류\nCode Signing 인증서 발급받으려 했던 code signing 인증서는 어플리케이션에 서명을 해서 해당 어플리케이션 publisher의 신원을 보장하는데 사용하기 때문에 내가 필요했던 server to server 커뮤니케이션에서 사용되는 인증서가 아니다.\ncode signing 인증서로 어플리케이션에 서명을 하게 되면 [Picture 3] 와 같이 사용자에게 어플리케이션 publisher 에 대한 정보가 추가로 제공이 된다.\n[Picture 3] code signing 인증서로 서명한 application\nCSR 생성하기 모든 SSL 인증서는 domain validation을 한다. 이 생각에 사로잡혀서 Root CA가 서명한 인증서를 발급받기 위해 제출해야 하는 CSR는 인증서가 사용이 될 서버에서 만들어야 한다고 생각했다.\n예를 들어 leelee.me 이라는 루트 도메인에서 사용하는 인증서라고 했을 때 leelee.me 도메인을 호스팅하는 서버에서 CSR을 생성해야 한다고 생각한 것이다. 하지만 CSR을 다른 서버에서 생성했다면, CSR을 생성할 때 함께 만든 private key를 인증서를 사용할 서버로 옮기면 된다.\n인증서의 종류 SSL Certificate VS Code Signing Certificate 공통점\nX.509 형태의 디지털 인증서다. PKI 형식을 사용한다. 두 인증서가 없다면 사용자에게 보안 경고가 띄워진다. 발급하기 전에 CA에서 발급요청자를 검증한다. end user들이 해킹등의 사이버 범죄에 노출되는 것을 방지하기 위해 사용된다. 차이점\nSSL Certificate은 두 시스템에서 오고가는 data를 암호화한다. Code Signing Certificate은 소프트웨어 자체를 hash \u0026amp; sign 한다. 모든 코드에 디지털 서명을 한 것과 마찬가지이며 만약 중간에서 누가 코드를 수정한다면 해시값이 변경이 되어 end user가 코드를 다운받기 전에 alert를 띄워 사전에 설치를 못 하도록 막는다. [Picture 4] 인증서 다이어그램\nSSL Certificate SSL Certificate는 크게 2가지 기준으로 분류할 수 있다.\n검증히려는 대상 커버하는 도메인의 개수 검증하려는 대상 검증 대상에 따라서 암호화하는 방식이 달라지거나 하지 않는다. 따라서 저렴하게 발급받은 DV와 비싸게 발급받은 EV가 결국 보안의 관점에서는 큰 차이가 없다.\n하지만 검증받은 대상의 identiy가 다르기 때문에 DV는 작은 서비스에서 사용하기가 용이하고 그 외에 e-commerce나 중요한 정보를 주고 받아야 하는 서비스의 경우에는 다른 인증서를 써야 한다.\nDomain Validation 도메인 소유권을 확인한다. 손쉽게 발급받을 수 있다. (최대 1일) 가장 많이 사용되는 SSL Certificate의 형태다. Let’s encrypt에서 발급하는 인증서도 DV로, OV나 EV 처럼 다른 인증을 받을 때는 사용할 수 없다. Organization Validation 도메인 소유권 + Organization 존재를 확인한다. 회사 같은 경우, 실제로 존재하는 회사인지를 확인하기 위해 관련 서류를 제출하기도 한다. 발급하는데 몇 시간 또는 며칠 정도가 소요된다. Extended Validation 도메인 소유권 + Organization 존재 확인 + 물리적인 추가 절차를 확인한다. SSL certification industry’s governing consortium 가이드라인을 준수해야 하는 등 발급 절차가 복잡하다. 커버하는 도메인의 개수 인증서에는 도메인이라는 말이 자주 등장하게 된다. 하지만 도메인이라는 단어 자체가 뜻하는 의미가 모호할 수 있기 때문에 혼선방지 차원에서 인증서에서는 FQDN 이라는 단어를 더 선호한다.\nFQDN은 Fully-Qualified Domain Name 의 약자로 도메인 전체 이름을 표기하는 방식을 뜻한다.\nFQDN 예시\n# 아래는 서로 동일한 도메인이다. www.leelee.co.kr leelee.co.kr www.sub.leelee.co.kr # 아래는 서로 다른 FQDN 이다. www.leelee.co.kr leelee.co.kr Single Domain 단 하나의 FQDN을 커버한다. Multiple Domain 여러개의 FQDN을 커버한다. 인증서를 등록할 때 SAN (Subject Alternative Name) 항목에 다수의 도메인을 입력한다. Wildcard Domain 하나의 Root Domain과 무제한의 서브도메인을 커버한다. wildcard는 하나의 전체도메인을 입력하지 않기 때문에 FQDN이라 하지 않았다. CA 업체에서는 비용에 따라서 커버하는 서브도메인 개수에 제한을 두기도 한다. * 을 사용해서 도메인을 커버한다. 커버하는 도메인 예시\n# Singple Certificate www.leelee.co.kr # Multi-Domain Certificate www.leelee.co.kr leelee.co.kr www.sub.leelee.co.kr # Wildcard Certificate *.leelee.co.kr 인증서와 관련된 개념 PKI PKI는 Public Key Infrastructure 의 약자로 공개키 기반구조라고 하며 디지털 인증서를 생성, 관리, 배포, 사용, 저장 및 파기, 공개키 암호화의 관리에 필요한 정책 등을 뜻한다. PKI는 아래의 항목을 전체로 하고 있다.\n비대칭 키 알고리즘을 이용한다. Private key, Public key pair 를 생성한다. Private key는 개인만 소유하며 밖으로 공개해서는 안된다. Public key는 공개하는 키로, 누구에게든 공개해도 된다. 비대칭 키 알고리즘 Private key, Public key 두 개의 키를 사용한다. 이처럼 Encryption(암호화)와 Decryption(복호화)에 두 개의 다른 키를 쓰기 때문에 비대칭 키라고 한다. 대표적인 알고리즘으로는 RSA가 있다.\n적용 시나리오 Public key를 이용해 암호화 : 데이터 보안 사용자 B가 사전에 공유받은 사용자 A의 public key를 이용하여 데이터를 암호화한다. 사용자 A의 public key로 암호화된 데이터는 오직 사용자 A의 private key로 복호화 할 수 있다. 사용자 A의 private key는 사용자 A만 소유하고 있기 때문에 사용자 B는 사용자 A만 볼 수 있는 데이터를 전송하게 된 것이다. [Picture 5] Public key를 이용한 암호화\nPrivate key를 이용해 암호화 : 신원인증 사용자 A의 private key로 암호화 된 데이터는 사용자 A의 public key를 이용해야만 복호화를 할 수 있다. 데이터가 사용자 A의 public key로 복호화가 안된다면 사용자A가 보냈다는 것을 인증할 수 없다. 사용자 A의 public key로 데이터를 복호화할 수 있다면 사용자 A가 보냈다는 것을 인증할 수 있다. [Picture 6] Private key를 이용한 암호화\n해커가 암호화된 데이터를 도청할 경우 사용자 A의 private key가 없기 때문에 해커가 중간에서 데이터를 복호화ㅊ할 수 없다. [Picture 7] 해킹 시도\nPKI에서 가능한 두 가지 방식의 네트워크 보안 public key를 이용해 암호화 하면 원하는 상대방에게만 데이터를 공개할 수 있다. from 사용자 B → to 사용자 A private key를 이용해 암호화 하면 신원 인증을 할 수 있다. from 사용자 A → to 사용자 B X.509 X.509는 디지털 인증서 생성 관련 국제 표준을(format)을 의미한다. X.509를 사용하는 네트워크 노드들은 전세계적으로 약속된 x.509 국제 표준을 방식으로 디지털 ID를 생성해 서로의 신원을 증명할 수 있다.\nX.509는 인터넷의 다양한 분야에서 신원 확인을 위해 광범위하게 사용되고 있는 가장 유명한 디지털 신원 증명 방식이다.\nX.509 version 3 인증서 양식 [Picture 8] X.509 인증서 양식\nKey usage extension 인증서에 포함되어있는 public key의 목적을 나타낸다. Key usage extension을 설정해 public key의 사용처를 제한할 수 있다.\nKey usage extension 예시\n인증서가 서명을 하거나 signature를 검증하기 위해 사용된다면 Key usage extension으로 Digital signature와 Non-repudication 를 설정한다. 인증서가 key 관리를 위해서만 사용이 된다면 key encipherment를 설정한다. [Picture 9] Key usage extension 종류\nExtended key usage Key usage extension이 기본적인 인증서의 사용 목적(purpose)를 나타내는 것이라면 Extended key usage는 인증서의 additional한 사용 목적을 나타낸다. 보통 Extended key usage는 end entity의 인증서에만 표시가 된다.\nExtended key usage 예시\ncritical이라면 인증서는 설정되어있는 용도로만 사용을 해야 한다. 해당 인증서를 다른 용도로 사용 했을 경우에는 CA 정책에 위반된다. non-critical 이라면 설정되어있는 용도 외의 다른 용도로 사용 했을 경우에도 CA의 제한에 걸리지 않는다. 또한 다수의 kye/certificate을 가지고 있는 entity라면 맞는 key/certificate를 찾는데에도 사용이 될 수 있다. [Picture 10] Extend key usage extension 종류\nCSR Certificate Signing Request의 약자이다. CA에 인증서를 서명해달라고 요청할 때 사용이 된다. 인증서 발급할 때만 사용이 되고, 인증서가 발급된 후에는 별도로 사용 되지 않는다. Private Key PKI의 핵심이 되는 비밀키이다. 만료 기간이 별도로 존재하지 않는다. Public Key PKI의 또 다른 핵심이 되는 공개키이다. Public Key라고 따로 파일이 존재하기 보다는 Certificate에 포함이 되어있다. 때문에 public key와 certificate을 혼용해서 쓴다. 만료 기간이 별도로 존재하지 않는다. Certificate public key와 각종 정보를 담고 있는 인증서로, x.509 형식으로 되어있다. 만료 기간이 존재한다. 때문에 인증서가 만료되면 새로운 인증서를 발급받아야 한다. PKI File Extension PEM (Privacy Enhanced Mail) 형식 은 가장 흔하게 사용되는 X.509 인증서 형식인데 .crt, .pem, .cer, .key 확장자 모두가 PEM 형식이다. \u0026mdash;\u0026ndash;BEGIN CERTIFICATE\u0026mdash;\u0026ndash; 로 시작한다.\n.cert *.crt Certificate를 위한 확장자다. Base64 encoded X.509 certificate DER encoded X.509 certificate 해당 확장자들은 Private key를 지원하지 않는다. .key Private key 확장장다. .pem Certificate를 위한 확장자다. .crl Certificate Revoke List를 위한 확장자다. Certificate Revoke List는 폐기된 인증서의 목록이며, CA는 CRL을 통해 폐기된 인증서를 관리한다. .csr Certificate Singing Request를 위한 확장자다. .der Certificate을 위한 인증서 확장자인데, DER encoded X.509 Certificate에 한정된다. 해당 확장자는 Private key를 지원하지 않는다. 보통의 인증서들과 달리 ----BEGIN CERTIFICATE----- 로 시작하지 않는다. Java contexts에서 자주 사용이 된다. .der 인증서 예시\n3082 07fd 3082 05e5 a003 0201 0202 1068 1604 dff3 34f1 71d8 0a73 5599 c141 7230 0d06 092a 8648 86f7 0d01 010b 0500 3072 310b 3009 0603 5504 0613 0255 5331 0e30 0c06 0355 0408 0c05 5465 7861 7331 1030 0e06 0355 0407 0c07 486f 7573 746f 6e31 1130 0f06 0355 040a 0c08 5353 4c20 436f 7270 312e 302c 0603 5504 030c 2553 534c 2e63 6f6d 2045 5620 5353 4c20 496e 7465 726d 6564 6961 7465 2043 4120 5253 4120 ","date":"2022-06-15","permalink":"https://leeleelee3264.github.io/post/2022-06-15-digital-certificate-part-one/","tags":["Infra"],"title":"Digital certificate"},{"content":"\n책 [Effective Python] better way를 1장부터 5장까지 요약한다.\nIndex\n사용중인 파이썬의 버전을 알아두라 PEP8 스타일 가이드를 따르라 bytes와 str의 차이를 알아두라 C 스타일 형식 문자열을 str.format과 쓰기보다는 f-문자열을 통한 인터플레이션을 사용하라 복잡한 식을 쓰는 대신 도우미 함수를 작성하라 사용중인 파이썬의 버전을 알아두라 파이썬 버전 콘솔 명령어 예시\n1 python --version 파이썬 버전 코드 예시\n1 2 3 4 5 6 7 import sys print (sys.version_info) \u0026gt;\u0026gt;\u0026gt; sys.version_info(major=3, minor=8, micro=12, releaselevel=\u0026#39;final\u0026#39;, serial=0) print(sys.version) \u0026gt;\u0026gt;\u0026gt; 3.8.12 (default, Oct 22 2021, 17:47:41) \u0026gt;\u0026gt;\u0026gt;[Clang 13.0.0 (clang-1300.0.29.3)] 파이썬2 파이썬2는 2020년 1월 1일부로 수명이 다했다. 이제 더이상 버그수정, 보안 패치가 이뤄지지 않는다. 공식적으로 지원을 하지 않은 언어이기 때문에 사용에 대한 책임은 개발자에게 따른다.\n파이썬2로 작성된 코드를 사용해야 한다면 2to3, six와 같은 라이브러리의 도움을 받아야 한다.\nsix 사용 예시\n1 2 3 4 return ( six.text_type(user.pk) + six.text_type(timestamp) + six.text_type(user.username) + six.text_type(user.uuid) + six.text_type(user.type) ) PEP8 스타일 가이드를 따르라 PEP8는 파이썬 코드를 어떤 형식으로 작성할지 알려주는 스타일 가이드다. 문법만 올바르다면 어떤 방식으로 원하든 파이썬 코드를 작성해도 좋지만, 일관된 스타일을 사용하면 코드에 더 친숙하게 접근하고, 코드를 더 쉽게 읽을 수 있다.\nPEP8 스타일 가이드 공백 탭 대신 스페이스를 사용해 들여쓰기를 하라. 문법적으로 중요한 들여쓰기에는 4칸 스페이스를 사용하라. 라인 길이는 79개 문자 이하여야 한다. 긴 식을 다음 줄에 이어서 쓸 경우에는 일반적인 들여쓰기보다 4스페이스를 더 들여써야 한다. 파일 안에서 각 함수와 클래스 사이에는 빈 줄 두 줄 넣어라. 클래스 안에서 메서드와 메서드 사이에는 빈 줄을 한 줄 넣어라. dict에서 키와 콜론(:) 사이에는 공백을 넣지 않고, 한 줄 안에 키와 값을 같이 넣는 경우에는 콜론 다음에 스페이스를 하나 넣는다. 변수 대입에서 = 전후에는 스페이스를 하나씩만 넣는다. 타입 표기를 덧붙이는 경우에는 변수 이름과 콜론 사이에 공백을 넣지 않도록 주의하고, 콜론과 타입 정보 사이에는 스페이스를 하나 넣어라. 공백 예시\n1 2 def add(a: int, b: int): return a + b 명명 규약 (name convention) 함수, 변수, 애트리뷰트 명명 규약 함수, 변수, 애트리뷰트는 lowercase_underscore 처럼 소문자와 밑줄을 사용해야 한다. snake case 모듈 수준의 상수는 ALL_CAPS처럼 모든 글자를 대문자로 하고, 단어와 단어 사이를 밑줄로 연결한 형태를 사용한다. private 명명 규약 보호해야(protect) 하는 인스턴스 애트리뷰트는 일반적인 애트리뷰트 이름 규칙을 따르되, 밑줄로 시작한다. private 인스턴스 애트리뷰는 밑줄 두 줄로 시작한다. 밑줄 두 줄은 maigc method를 위한 컨벤션인줄 알았는데, 클래스에서 private 메소드와 애트리뷰트를 밑줄 두줄로 만든다. 파이썬에서 private, protect 모두 정식 지원을 하지 않기 때문에, 가독성을 위한 네임 컨벤션에 더 가깝다. 클래스 명명 규약 클래스와 예외는 CapitalizedWord 처럼 여러 단어를 이어 붙이되, 각 단어의 첫 글자를 대문자로 만든다. PascalCase, CamelCase 클래스에 들어있는 인스턴스 메서드는 호출 대상 객체를 가리키는 첫번쨰 인자의 이름으로, 반드시 self를 사용해야한다. 자기자신을 가르키기 때문에 클래스 메서드는 클래스를 가르키는 첫 번째 인자의 이름으로 반드시 cls를 사용해야 한다. 클래스 자체를 가르키기 때문에 함수, 변수 명명 예시\n1 2 3 4 _count = 100 def _add(a, b): return a + b private 인스턴스 명명 예시\n1 2 3 4 __count = 100 def __add(a, b): return a + b 식과 문 읽기 쉬운 식 작성 긍정적인 식을 부정하지 말고, 부정을 내부에 넣어라. 한 줄짜리 if 문이나 한 줄짜리 for, while 루프, 한 줄 짜리 except 복합문을 사용하지 말라. 명확성을 위해 각 부분을 여러 줄에 나눠 배치하라. 식을 한 줄 안에 다 쓸 수 없는 경우, 식을 괄호로 둘러싸고 줄바꿈과 들여쓰기를 추가해서 읽기 쉽게 만들라. 여러 줄에 걸쳐 식을 쓸 때는 줄이 계속된다는 표시를 하는 \\ 문자 보다는 괄호를 사용하라. editor를 사용하다보면 이렇게 \\ 되는 형식을 많이 사용하는데, PEP8에서 권장하지 않은 형태였다니, 앞으로 ()를 써보도록 노력하겠다. 빈 컨테이너 확인 빈 컨테이너나 시퀸스([], ‘’)등을 검사할 때는 길이를 0과 비교하지 말라. 빈 컨테이너나 시퀸스 값이 암묵적으로 False 취급된다는 사실을 활용해라. 파이썬을 자바와 동실시 해서, 얼마전에 str ≠ ‘’ 로 비어있는 여부를 검사한 적이 있다. 파이썬에서 비어있는 str는 False 취급이라는 것을 꼭 기억하자. 마찬가지로 비어 있지 않은 컨테이너나 시퀸스([1], ‘hi’) 등을 검사할 때는 길이를 0과 비교하지 말라. 컨테이너가 비어있지 않은 경우 암묵적으로 True 평가가 된다는 사실을 활용해라. 내부 부정 예시\n1 2 3 4 5 6 7 8 # 긍정적인 식을 부정 if not a is b: # 부정을 내부에 넣음 if a is not b: # 비교 대상이 없이 자기 자신만 있을 때는 이렇게 해도 된다. if not a: 빈 컨테이너 확인 예시\n1 2 3 4 5 6 7 8 9 10 11 12 d = {} st = \u0026#39;\u0026#39; if not d: if not st: # Don\u0026#39;t do 1 if str == \u0026#39;\u0026#39;: # Dont\u0026#39;do 2 if len(d) == 0: 임포트 임포트 문은 평소에 정말 신경을 쓰지 않았는데, 앞으로는 editor에서 어떻게 임포트를 하는지 보고, 신경 써서 작성하도록 하자.\nimport 문을 항상 파일 맨 앞에 위치시켜라. 모듈을 임포트할 때는 절대적인 이름을 사용하고, 현 모듈의 경로에 상대적인 이름은 사용하지 말라. 반드시 상대적인 경로로 임포트를 해야 하는 경우에는 명시적인 구문을 사용하라. 임포트 순서 임포트를 적을 때는 아래와 같은 순서로 섹션을 나누고, 각 세션은 알파벳 순서로 모듈을 임포트하라. 표준 라이브러리 모듈 서드 파티 모듈 여러분이 만든 모듈 임포트 예시\n1 2 3 4 5 6 # bar 패키지에서 foo 모듈을 임포트 하려고 할 때 # Do from bar import foo # Don\u0026#39;t do import foo 상대 경로 임포트 예시\n1 from . import foo 결론 개인 프로젝트를 할 때에도 pylint, flake8 등의 파이썬 lint를 이용해서 스타일을 준수하도록 노력하자.\nbytes와 str의 차이를 알아두라 파이썬에는 문자열 데이터의 시퀸스를 표현하는 두 가지 타입 bytes와 str이 있다.\nbytes 부호가 없는 8바이트 데이터가 그대로 들어가거나, 아스키 인코딩을 사용해 내부 문자를 표시한다.\nbytes 예시\n1 2 a = b\u0026#39;h\\x6511o\u0026#39; c = b\u0026#39;eojwpkmcdlklksm\u0026#39; str 사람이 사용하는 언어의 문자를 표현하는 유니코드 코드 포인트가 들어간다.\n인코딩 str에는 직접 대응하는 이진 인코딩이 없고, bytes에는 직접 대응하는 텍스트 인코딩이 없다.\n때문에 함수를 호출해야 한다.호출 할 때 여러분이 원하는 인코딩 방식을 명시적으로 지정할 수 도 있고 시스템 디폴트 인코딩을 사용할 수 있는데 일반적으로 utf-8이 시스템 디폴트다.\n인코딩 시나리오 유니코드 데이터를 이진 데이터로 변환해야 할 때: str의 encode 메서드 호출 이진 데이터를 유니코드 데이터로 변환해야 할 때: bytes의 decode 메서드 호출 유니코드 샌드위치 유니코드 데이터를 인코딩하거나 디코딩하는 부분을 인터페이스의 가장 먼 경계 지점에 위치시켜라. 이런 방식을 유니코드 샌드위치라고 부른다.\n프로그램의 핵심 부분은 유니코드 데이터가 들어 있는 str를 사용해야 하고, 문자 인코딩에 대해 어떤 가정도 해서는 안된다.\n핵심 함수에는 이미 인코딩이 된 str이 인자로 전달되어야 한다. 이런 접근을 하면 다양한 텍스트 인코딩으로 입력 데이터를 받아들일 수 있고, 출력 텍스트 인코딩은 한 가지로 엄격하게 제한할 수 있다. [Picture 1] 유니코드 샌드위치 블랙박스\nstr 반환 유니코드 샌드위치 예시\n1 2 3 4 5 6 7 def to_str(bytes_or_str): if isinstance(bytes_or_str, bytes): value = bytes_or_str.decode(\u0026#39;utf-8) else: value = bytes_or_str return value bytes 반환 유니코드 샌드위치 예시\n1 2 3 4 5 6 7 def to_bytes(bytes_or_str): if isinstanceof(bytes_or_str, str): value = bytes_or_str.endode(\u0026#39;utf-8\u0026#39;) else value = bytes_or_str return value 파이썬에서 bytes와 str을 다룰 때 기억해야 하는 점 연산 bytes와 str이 똑같이 작동하는 것처럼 보이지만 각각의 인스턴스는 서로 호환되지 않기 때문에 전달중인 문자 시퀸스가 어떤 타입인지 알아야 한다.\n연산 불가항목 예시\n1 2 3 bytes + str bytes \u0026gt; str b\u0026#39;foo\u0026#39; == \u0026#39;foo\u0026#39; \u0026gt;\u0026gt;\u0026gt; False 파일 (내장함수 open을 호출해 얻은) 파일 핸들과 관련한 연산들이 디폴트로 유니코드 (str) 문자열을 요구하고, 이진 바이트 문자열을 요구하지 않는다.\n이진 쓰기 모드 (’wb’)가 아닌 텍스트 쓰기 모드 (’w’) 로 열면 오류가 난다. bytes로 파일 읽기, 쓰기를 하고 싶다면 이진 읽기모드 (’rb’) 또는 이진 쓰기모드 (’wb’)를 써야 한다.\n파일 불가항목 예시\n1 2 3 4 5 with open(\u0026#39;data.bin\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(b\u0026#39;\\xf1\\xf2\\xf3\u0026#39;) \u0026gt;\u0026gt;\u0026gt; Traceback ... TypeError: write() argument must be str, not bytes. 파일 시스템의 디폴트 텍스트 인코딩을 bytes.encode(쓰기), str.decode(읽기) 에서 사용하는데 utf-8이기 때문에 이진데이터의 경우 utf-8로 읽지 못하는 경우가 생겨 에러가 발생할 수 있다.\n이런 현상을 막고자, utf-8로 인코딩을 못하는 경우에는 읽어올 때 인코딩을 아예 명시해주는 경우도 있다.\n인코딩 명시 예제\n1 2 with open(\u0026#39;data.bin\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;cpl252\u0026#39;) as f: data = f.read() 결론 시스템 디폴트 인코딩을 항상 검사하도록 하자.\n1 python3 -c \u0026#39;import locale; print(locale.getpreferredencoding())\u0026#39; C 스타일 형식 문자열을 str.format과 쓰기보다는 f-문자열을 통한 인터플레이션을 사용하라. 형식화는 미리 정의된 문자열에 데이터 값을 끼워 넣어 사람이 보기 좋은 문자열로 저장하는 과정이다. 파이썬에서는 f-문자열을 통한 인터플레이션 빼고는 각자의 단점이 있다.\n형식 문자열 % 형식화 연산자를 사용한다. 왼쪽에 들어가는 미리 정의된 텍스트 템플릿을 형식 문자열이라고 부른다. C 함수에서 비롯된 방법이다.\n형식 문자열 예시\n1 print(\u0026#39;이진수: %d, 십육진수: %d\u0026#39;, %(a, b)) 형식 문자열 문제점 형식화 식에서 오른쪽에 있는 값들의 순서를 바꾸거나, 타입을 바꾸면 포멧팅이 안되어 오류가 발생한다. 형식화를 조금이라도 변경하면 식이 매우 복잡해 읽기가 힘들다. 같은 값을 여러번 사용하고 싶다면 오른쪽 값을 여러번 복사해야 한다. 내장 함수 format과 str.format 파이썬 3부터는 %를 사용하는 오래된 C스타일 형식화 문자열보다 더 표현력이 좋은 고급 문자열 형식화 기능이 도입됐다. 이 기능은 format 내장 함수를 통해 모든 파이썬 값에 사용할 수 있다.\nformat 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 key = \u0026#39;my_var\u0026#39; value = 1.234 formatted = \u0026#39;{} = {}\u0026#39;.format(key, value) print(formatted) \u0026gt;\u0026gt;\u0026gt; my_var = 1.234 # format 메서드에 전달된 인자의 순서를 표현하는 위치 인덱스를 전달할 수도 있다. formatted = \u0026#39;{1} = {0}\u0026#39;.format(key, value) print(formatted) \u0026gt;\u0026gt;\u0026gt; 1.234 = my_var # 형식화 문자열 안에서 같은 위치 인덱스를 여러 번 사용할 수도 있다. formatted = \u0026#39;{}는 음식을 좋아해. {0}가 요리하는 모습을 봐요\u0026#39;.format(name) print(formatted) \u0026gt;\u0026gt;\u0026gt; 철수는 음식을 좋아해. 철수가 요리하는 모습을 봐요. format 문제점 C 스타일의 형식화와 마찬가지로, 값을 조금 변경하는 경우에는 코드 읽기가 어려워진다. 가독성 면에서 거의 차이가 없으며, 둘 다 읽기에 좋지 않다. 인터폴레이션을 통한 형식 문자열 (f-문자열) 위의 문제들을 완전히 해결하기 위해 파이썬 3.6 부터는 인터폴레이션을 통한 형식 문자열 (짧게 f-문자열)이 도입되었다. 이 새로운 언어 문법에서는 형식 문자열 앞에 f 문자를 붙여야 한다. 바이트 문자열 앞에 b 문자를 붙이고, raw 문자열 앞에 r문자를 붙이는 것과 비슷하다.\nf-문자열은 형식화 식 안에서 현재 파이썬 영역에서 사용할 수 있는 모든 이름을 자유롭게 참조할 수 있도록 허용함으로써 이런 간결함을 제공한다.\nf-문자열 예시\n1 2 3 4 5 6 7 8 key = \u0026#39;my_var\u0026#39; value = 1.234 formatted = f\u0026#39;{key} = {value}\u0026#39; print(formatted) \u0026gt;\u0026gt;\u0026gt; my_var = 1.234 파이썬에서 제공하는 형식화 문법의 차이 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # f-문자열 f_string = f\u0026#39;{key:\u0026lt;10} = {value: .2f}\u0026#39; # c 스타일 c_tuple = \u0026#39;%-10s = %.2f\u0026#39; % (key, value) # c 스타일 + 딕셔너리 c_dict = \u0026#39;%{key}-10s = %{value}.2f\u0026#39; % {\u0026#39;key\u0026#39;: key, \u0026#39;value\u0026#39;: value} # str.format str_args = \u0026#39;{:\u0026lt;10} = {value: .2f}\u0026#39;.format(key, value) # str.format + 키워드 인자 str_kw = \u0026#39;{key:\u0026lt;10} = {value:.2f}\u0026#39;.format(key=key, value=value) 결론 f-문자열은 간결하지만, 위치 지정자 안에 임의의 파이썬 식을 직접 포함시킬 수 있으므로 매우 강력하다. 값을 문자열로 형식화해야 하는 상황을 만나게 되면 다른 대안 대신 f-문자열을 택하라.\n복잡한 식을 쓰는 대신 도우미 함수를 작성하라. 파이썬은 문법이 간결하므로 상당한 로직이 들어가는 식도 한 줄로 매우 쉽게 작성할 수 있다. 예를 들어 URL의 query string를 파싱하고 싶다고 하자.\nquery string 파싱 예시\n1 2 3 4 5 6 7 8 from urllib.parse import parse_qs my_values = parse_qs(\u0026#39;빨강=5\u0026amp;파랑=0\u0026amp;초록=\u0026#39;, keep_blank_values=True) print(repr(my_values)) \u0026gt;\u0026gt;\u0026gt; {\u0026#39;빨강\u0026#39;: [\u0026#39;5\u0026#39;], \u0026#39;파랑\u0026#39;: [\u0026#39;0\u0026#39;], \u0026#39;초록\u0026#39;: [\u0026#39;\u0026#39;] } 이런 때에 파라미터가 없거나 비어 있을 경우 0이 디폴트 값으로 대입되면 좋을 것이다. 여러 줄로 작성해야 하는 if 문(if statement)를 쓰거나 도우미 함수를 쓰지 않고, if 식(if expression)으로 한줄로 처리 할 수 있다.\n뿐만 아니라, 모든 파라메터 값을 정수로 변환해서 즉시 수식에서 활용하기를 바란다고 해보겠다. 그럼 식은 아래와 같아진다.\n한 줄 대입, 변환 예시\n1 2 3 red = int(my_values.get(\u0026#39;빨강\u0026#39;, [\u0026#39;\u0026#39;])[0] or 0) green = int(my_values.get(\u0026#39;초록\u0026#39;, [\u0026#39;\u0026#39;])[0] or 0) opacity = int(my_values.get(\u0026#39;투명도\u0026#39;, [\u0026#39;\u0026#39;])[0] or 0) 현재 이 코드는 너무 읽기 어렵고 시각적 잡음도 많다. 즉, 코드를 이해하기 쉽지 않으므로 코드를 새로 읽는 사람이 이 식이 실제로 어떤 일을 하는지 이해하기 위해 너무 많은 시간을 투자해야 한다.\n코드를 짧게 유지하면 멋지기는 하지만, 모든 내용을 한줄에 우겨 넣기 위해 노력할 만큼의 가치는 없다.\n명확하게 바꾼 코드 예시\n1 2 3 4 5 6 7 def get_first_int(values, key, default=0): found = values.get(key, [\u0026#39;\u0026#39;]) if found[0]: return int(found[0]) return default 식이 복잡해지기 시작하면 바로 식을 더 작은 조간으로 나눠서 로직을 도우미 함수로 옮길지 고려해야 한다. 특히 같은 로직을 반복해 사용할 때는 도우미 함수를 꼭 사용하라. 아무리 짧게 줄여 쓰는 것을 좋아한다 해도, 코드를 줄여 쓰는 것보다 가독성을 좋게 하는 것이 더 가치 있다.\n결론 파이썬의 함축적인 문법이 지저분한 코드를 만들어내지 않도록 하라. 반복하지 말라는 뜻의 DRY 원칙을 따르라.\n","date":"2022-05-06","permalink":"https://leeleelee3264.github.io/post/2022-05-06-effective-python-betteryway-1-to5/","tags":["Book"],"title":"[Effective Python] Chapter 1: 1장부터 5장까지의 요약"},{"content":"\n책 [Introducing Python] 절반을 요약한다.\nIndex\n파이 맛보기 파이 재료: 숫자, 문자열 변수 파이 채우기: 리스트, 튜플, 딕셔너리, 셋 파이 크러스트: 코드 구조 파이 포장하기: 모듈, 패키지, 프로그램 파이 맛보기 파이썬은 인터프리터 언어다. 파이썬이 개발을 빠르게 할 수 있다는 이유도 거대한 크기의 기계어를 만들어내지 않고 실행이 가능하기 때문으로 추정된다.\n인터프리터 언어 대표적인 인터프리터 언어는 파이썬, 자바 스크립트가 있다. 인터프리터는 소스코드를 바로 실행한다. 인터프리터는 바로바로 실행을 하다보니 처음에 속도가 비교적 빠르다. 컴파일 언어 대표적인 컴파일 언어는 자바다. 컴파일 언어는 처음 프로그램을 시작할 때 모든 코드를 기계어로 바꾼다 (컴파일 한다). 컴파일을 하기 때문에 처음에 프로그램을 실행할 때 시간이 오래 걸린다. 하지만 한 번 컴파일을 하면 실행시 기계어를 불러와 더 빨리 실행을 할 수 있어 매번 실행시마다 번역을 거치는 인터프리터 언어보다 속도가 더 빨라진다. 파이 재료: 숫자, 문자열 변수 파이썬은 문자를 변형 할 수 없다. st[0] = \u0026rsquo;e\u0026rsquo; 이런식으로 변경을 할 수 없다. 즉, 불변객체이다.\n문자열도 중간에 수정을 할 수 없고 아예 객체를 새로 만드는 replace() 메서드를 이용해서 문자열을 변경해야 한다. 문자열을 불변으로 만드는 이유는 Java와 마찬가지로 프로그래밍을 편리하게 하기 위해서다.\n슬라이싱을 이용한 문자 reverse 예시\n1 2 st = \u0026#34;eererewrvfgrhfos\u0026#34; re_st = st[::-1] # sofhrgfvrwereree 파이 채우기: 리스트, 튜플, 딕셔너리, 셋 파이썬에서 기본으로 제공하는 자료구조에 대해 알아본다.\ndel 자료구조에서 항목을 삭제하는 커맨드는 del 인데, 이 del은 자료구조의 함수가 아닌 파이썬 구문이다. del은 객체로부터 이름을 분리하고 객체의 메모리를 비워준다.\ndel 예시\n1 2 3 del full[2] # full.del(2) 처럼 쓰지 못한다. 리스트 리스트는 변경 가능하다. 항목을 할당하고, 자유롭게 수정 삭제를 할 수 있다.\n리스트 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 생성 empty = [] empyt2 = list() full = [1, 2, 3] # 리스트의 끝에 항목 추가하기 append() full.appned(4) # 리스트 병합하기 extend() added = [5, 6, 7, 8] full.extend(added) # [1, 2, 3, 4, 5, 6, 7, 8] full += added # [1, 2, 3, 4, 5, 6, 7, 8] # append 를 쓰면 리스트 자체가 추가된다 full.appned(added) # [1, 2, 3, 4, [5, 6, 7, 8]] # 리스트 정렬 # sort()는 리스트 자체를 내부적으로 정렬한다. # sorted() 는 리스트의 정렬된 복사본을 반환한다. full.sort() new_sort = full.sorted() 튜플 튜플은 불변한다. 튜플에 항목을 할당하고 나서는 바꿀 수 없다. 때문에 튜플을 상수 리스트라 볼 수 있다.\n튜플 예시\n1 2 3 4 5 6 7 8 9 10 # 생성 empty_tuple = () # 콤마로 값을 나열해도 튜플을 만들 수 있다. empty_tuple = 1, 2, 3 empty_tuple = (1, 2, 3) # 튜플의 나열하는 특성을 이용해서 객체 생성없이 swap하기 password = \u0026#39;12\u0026#39; icecream = \u0026#39;sweet\u0026#39; password, icecream = icecream, password 리스트가 아닌 불변객체라 함수 지원이 더 적은 튜플을 사용하는 이유 더 적은 공간을 사용한다. 실수로 값을 바꿀 위험이 없다. 튜플을 딕셔너리 키로 사용이 가능하다. 네임드 튜플 은 객체의 대안이 될 수 있다. 함수의 인자들은 튜플로 전달된다. 딕셔너리 딕셔너리 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 생성 empty_dict = {} # dict() 를 이용해 두 값 쌍으로 이뤄진 자료구조를 딕셔너리로 변환할 수 있다. lol = [[\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;], [\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;]] lol2 = lol #{\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;} lol3 = (\u0026#39;ab\u0026#39;, \u0026#39;cb\u0026#39;) lol4 = lol #{\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;} # 딕셔너리 결합하기 update() em = {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;} em2 = {\u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;} em.update(em2) # {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;} # 딕셔너리 비우기 em.clear() # 딕셔너리에 특정 키가 들어있나 확인 \u0026#39;c\u0026#39; in em # 모든 키 가져오기 em.keys() # 모든 값 가져오기 em.values() # 모든 키, 값 가져오기 # (\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;), (\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;) 처럼 튜플로 반환한다 em.items() 셋 어떤 것이 존재하는지 여부만 판단하기 위해서 셋을 사용한다. 중복을 허용하지 않는다. 셋은 수학시간에 배웠던 집합과 아주 유사하다.\n셋 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 생성 # 그냥 {} 는 딕셔너리 생성자에 선점되었다. empty_set = set() empty_set2 = {1, 2, 3, 4} # 각종 집합 # 교집합 \u0026amp;, intersection() if contents \u0026amp; {\u0026#39;ice\u0026#39;, \u0026#39;cream\u0026#39;} # ice 와 cream 모두 들어있어야 참 a = {1, 2} b = {3, 4} a \u0026amp; b = 2 # 합집합 |, union() a | b = {1, 2, 3} # 차집합 -, difference() a - b = {1} # 대칭 차집합 ^, symmetric_difference # 각 항목에 별개로 가지고 있는 값을 구한다. a ^ b = {1, 3} # 부분집합 \u0026lt;=, issubset() a.issubset(b) # False a.issubset(a) # True a.issubset((1, 2, 3)) # 슈퍼셋 \u0026gt;=, issuperset() a.issuperset((1)) # True ((1, 2, 3)).issuperset(a) # True a.issuperset(a) # True 파이 크러스트: 코드 구조 컴프리헨션 내가 가끔 검색해보고는 하는 한 줄 로 for 문 돌리기와 유사하다.\n하나 이상의 이터레이터로부터 파이썬 자료구조를 만드는 방법이다. 더 파이써닉한 용법이라니는데 간단한 할당문 말고는 컴프리헨션을 사용하면 더 헷갈릴 것 같다.\n한 줄 for 문 예시\n1 num = [i for i in range(1, 6)] 인자 다른 언어들과 마찬가지로, 값을 순서대로 상응하는 매개변수에 복사하는 것이 위치인자이다. 키워드인자는 위치인자의 혼동을 피하기 위해 상응하는 이름을 인자 안에 지정한 것이다.\n인자 예시\n1 2 3 4 5 6 7 8 9 10 11 # 위치 인자 def menu(wine, entree, dessert): pass # 키워드 인자 def menu(wine=wine, entree=entreee, dessert=dessert): pass # 인자의 기본 값 지정 def menu(wine, entree, dessert=\u0026#39;pie\u0026#39;): pass 인자 모으기 예시\n1 2 3 4 5 6 7 8 9 10 11 12 # 위치 인자 모으기 * def print_args(one, two, three, *args): pass # 실제로 호출 시 three까지 위치에 따라 값이 들어가고 나머지는 *args가 인자를 취하게 해준다. print_args(1, 2, 3, 4, 5, 6, 7, 8) # 키워드 인자 모으기 ** def print_keyword(**kwargs) # 실제 호출 시 위치인자와 마찬가지로, 함수에 따로 정의가 안 된 위치인자를 취한다. print_keyword(one=1, two=2, three=3, four=4, five=5) 여러가지 종류의 인자들을 섞어서 사용하려면 함수를 정의할 때 위치인자, 키워드 인자, *args, **kwargs 순으로 정의를 해줘야한다.\ndocstring 파이썬 문서화에 관련된 부분. 일반 주석은 #을 사용하지만, 모듈과 클래스와 메소드에 사용하는 주석의 형태는 따로 있다. 이것을 doctstring 이라고 한다.\ndocstring 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026#34;\u0026#34;\u0026#34; 모듈 (파이썬 파일) 최상단에 이런 형식으로 주석을 달아주세요. Usage: python my_test.py \u0026lt;param\u0026gt; \u0026#34;\u0026#34;\u0026#34; class TestClass: \u0026#34;\u0026#34;\u0026#34; 클래스 아래에 이런 형식으로 주석을 달아주세요. \u0026#34;\u0026#34;\u0026#34; def test_method(): \u0026#34;\u0026#34;\u0026#34; 함수 아래에 이런 형식으로 주석을 달아주세요.\t\u0026#34;\u0026#34;\u0026#34; pass docstring을 이용해서 주석을 달아두면 코드에서 help 함수를 사용해 접근을 할 수 있다.\n내가 지금 사용하는 클래스가 뭘 하는 애인지 해당 클래스 파일을 읽지 않아도 콘솔에 입력만 하면 볼 수 있다는 장점이 있다.\nhelp 함수로 docstring 접근 예시\n1 2 help(TestClass) TestClass.__doc__ 라인 유지하기 PEP 에 따르면 파이썬은 한 줄에 80글자를 넘으면 안된다. 가독성이 제일 중요한 언어에서 가독성이 떨어지기 때문이다. 그래서 긴 문장을 사용해야 할 때에는 백슬래시(\\)로 라인을 끊어준다.\n백슬래시 예시\n1 2 3 4 5 6 7 8 test = \u0026#34;this\u0026#34; + \\ \u0026#34;is very very\u0026#34; + \\ \u0026#34;long long line\u0026#34; # 추천하지 않는 라인 끊는 방법 test = \u0026#34;\u0026#34; test += \u0026#34;is very very\u0026#34; test += \u0026#34;long long line\u0026#34; 일등 시민 : 함수 함수는 뷸변하기 때문에 딕셔너리의 키로 사용할 수 있다.\n함수를 변수에 할당할 수 있고, 다른 함수에서 이를 인자로 쓸 수 있으며, 함수에서 함수를 반환할 수 있다. 파이썬에서 괄호 ()는 함수를 호출 한다는 의미로 사용되고, 괄호가 없으면 함수를 객체 처럼 간주한다.\n함수에서 함수를 반환하는 예시\n1 2 3 4 5 6 7 8 def run_something_with_args(func, arg1, arg2): func(arg1, arg2) def add_args(arg1, arg2): return arg1 + agr2 \u0026gt;\u0026gt; run_something(add_agrs, 5, 8 ) 14 예제에서 run_something_with_args로 전달된 add_args 는 괄호 없이 객체처럼 취급되어 func 매개변수로 할당된다. 뒤에 괄호 () 가 붙은 func 는 전달 받은 arg1, arg2를 매개변수로 해 함수를 호출한다. 내부 함수 먼저 읽으면 좋을 자료 [Real Python: adding behavior with inner functions decorators] 함수 안에 또 다른 함수를 정의한다. 함수를 global scope 으로부터 완전히 숨겨 encapsulation을 하거나, 복잡한 작업을 하기 위해 Helper 함수를 만들어야 할 때 내부함수를 쓴다.\n내부 함수 예시\n1 2 3 4 5 6 7 def increment(number): def inner_increment(): return number + 1 return inner_increment() \u0026gt;\u0026gt; increment(10) 11 위처럼 작성을 하면 inner_increment 함수를 어디에서도 호출을 할 수 없다.\n내부 함수를 이용해 Helper를 만든 예시\n1 2 3 4 5 6 7 8 9 10 11 12 def factorial(number): if not isinstance(number, int): raise TypeError(\u0026#34;Sorry. \u0026#39;number\u0026#39; must be an integer.\u0026#34;) if number \u0026lt; 0: raise ValueError(\u0026#34;Sorry. \u0026#39;number\u0026#39; must be zero or positive.\u0026#34;) def inner_factorial(number): if number \u0026lt;= 1: return 1 return number * inner_factorial(number - 1) return inner_factorial(number) 그런데 내부함수로 Helper 함수를 만들기보다는 private 으로 Helper 함수를 만드는 것을 권장한다. private helper 함수가 훨씬 더 코드 읽기가 편하고 같은 모듈이나 클래스에서만 재사용이 가능하기 때문이다.\nprivate을 이용해 Helper를 만든 예시\n1 2 3 4 5 6 7 8 9 10 11 12 def factorial(number): if not isinstance(number, int): raise TypeError(\u0026#34;Sorry. \u0026#39;number\u0026#39; must be an integer.\u0026#34;) if number \u0026lt; 0: raise ValueError(\u0026#34;Sorry. \u0026#39;number\u0026#39; must be zero or positive.\u0026#34;) return _factorial(number) def _factorial(number): if number \u0026lt;= 1: return 1 return number * inner_factorial(number - 1) 클로저 클로저는 바깥 함수로부터 전달된 변수값을 저장하고, 변경을 할 수 있는 함수이다. 파이썬에서 함수를 변수에 할당할 수 있는 이유도 클로저 기능을 지원하기 때문이다.\n클로저 예시 generate_power\n1 2 3 4 5 6 7 8 9 10 11 12 # closure factory function def generate_power(exponent): def power(base): return base ** exponent return power raise_two = generate_power(2) \u0026gt;\u0026gt; raise_two(4) 16 \u0026gt;\u0026gt; raise_two(5) 25 클로저 호출 과정 상세 보기 클로저의 개념이 처음이다보니 제대로 이해가 가지 않아 print로 디버깅을 해가며 이해를 진행했다.\n클로저 예시 generate_power_with_debug\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def generate_power_with_debug(exponent): print(f\u0026#39;closure generated, passed exponent {exponent}\u0026#39;) def power(base): print(f\u0026#39;inner function in closure. passed base {base}\u0026#39;) return base ** exponent return power # closure 생성 raise_two = generate_power_with_debug(2) # closure 호출 print(f\u0026#39;result of closure : {raise_two(4)}\u0026#39;) # 콘솔에 출력된 결과 closure generated, passed exponent 2 inner function in closure. passed base 4 result of closure : 16 generate_power 호출 과정 (1)\n1 raise_two = generate_power_with_debug(2)) generate_power_with_debug 로 변수 exponent에 2를 넣어 클로저 생성한다. 클로저는 매번 호출될 때마다 새로운 클로저를 생성한다. 내부 함수 power은 호출이 되지 않고, 새로운 power 인스턴스를 생성해 리턴이 된다. 리턴값이 함수라는 얘기다. power를 리턴할 때 power의 surrounding state 를 스냅셧으로 남긴다. 여기에는 exponent 변수가 포함되어있다. generate_power 호출 과정 (2)\n1 print(f\u0026#39;result of closure : {raise_twon(4)}\u0026#39;) generate_power_with_debug 클로저를 호출한다. 클로저를 호출함에 따라 변수 base에 4를 넣어 내부함수 power가 호출한다. power는 클로저가 리턴되었을 때 함께 넘어왔던 surrounding state의 스냅샷에 저장이 된 exponent를 이용한다. power 결과를 리턴한다. 클로저 호출 시나리오 총정리\nQ: 어떻게 내부함수를 호출할 때 외부함수의 값에 접근을 할까? A: 클로저를 생성할 때 내부함수를 리턴하는데, 이때 외부함수의 상태 스냅샷을 함께 리턴해주기 때문이다. 클로저를 구분할 수 있는 부분은 내부함수를 괄호() 로 호출하지 않다는 것이다. 예제에서 power를 리턴하기만 하는데, 이렇게 리턴을 하면 exponent 값을 저장한 power 함수의 복사본을 주게 된다. 복사본을 할당 받은 변수 raise_two를 실제로 매개변수를 넣고 호출한다. 매개변수는 내부함수인 power 의 base 와 맵핑이 된다. 클로저로 권한 확인 함수 구현 클로저로 구현한 권한 확인 함수\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def has_permission(page): def permission(username): if username.lower() == \u0026#34;admin\u0026#34;: return f\u0026#34;\u0026#39;{username}\u0026#39; has access to {page}.\u0026#34; else: return f\u0026#34;\u0026#39;{username}\u0026#39; doesn\u0026#39;t have access to {page}.\u0026#34; return permission # 선언 check_admin_page_permision = has_permission(\u0026#34;Admin Page\u0026#34;) \u0026gt;\u0026gt;\u0026gt; check_admin_page_permision(\u0026#34;admin\u0026#34;) \u0026#34;\u0026#39;admin\u0026#39; has access to Admin Page.\u0026#34; \u0026gt;\u0026gt;\u0026gt; check_admin_page_permision(\u0026#34;john\u0026#34;) \u0026#34;\u0026#39;john\u0026#39; doesn\u0026#39;t have access to Admin Page.\u0026#34; 데코레이터 데코레이터는 callable(함수, 메소드, 클래스)를 인자로 받고, 다른 callable을 리턴한다(내부함수).\n생김새와 위치는 자바의 어노테이션과 동일하다. 데코레이션을 사용하면 이미 존재하고 있던 함수에 별도의 수정사항없이 액션을 추가 할 수 있다.\n데코레이터 사용 시나리오\n함수를 인자로 받는 callable을 선언한다. 인자로 받은 함수를 호출한다. 추가 액션이 있는 다른 함수를 리턴한다. 데코레이터 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def example_decorator(func): def _add_messages(): print(\u0026#39;This is my first decorator\u0026#39;) func() print(\u0026#39;bye\u0026#39;) # 데코레이터도 클로저처럼 내부함수를 괄호()로 호출하지 않는다. return _add_messages # greet = example_decorator(greet) 과 동일하다. 클로저 생성 형태와 동일하다. @example_decorator def greet(): print(\u0026#39;Hello World\u0026#39;) \u0026gt;\u0026gt;\u0026gt; greet() This is my first decorator Hello World bye 이렇게 추가로 액션을 행할 수 있게 해주는 데코레이터는 디버깅, 캐싱, 로깅, 시간측정(timing)에 많이 쓰인다.\n데코레이터 디버깅 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def debug(func): def _debug(*args, **kwargs): result = func(*args, **kwargs) print( f\u0026#34;{func.__name__}(args: {args}, kwargs: {kwargs}) -\u0026gt; {result}\u0026#34; ) return result return _debug @debug def add(a, b): return a + b \u0026gt;\u0026gt;\u0026gt; add(5, 6) add(args: (5, 6), kwargs: {}) -\u0026gt; 11 11 데코레이터로 구현한 generate_power\n아까 위에서는 클로저로 generate_power를 구현했는데 이번에는 데코레이터로 구현을 했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def generate_power(exponent): def power(func): def inner_power(*args): base = func(*args) return base ** exponent return inner_power return power @generate_power(2) def raise_two(n): return n \u0026gt;\u0026gt;\u0026gt; raise_two(7) 49 @generate_power(3) def raise_three(n): return n \u0026gt;\u0026gt;\u0026gt; raise_three(5) 125 데코레이터 호출 과정 상세 보기 데코레이터로 구현한 generate_power_with_debug\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def generate_power_with_debug(exponent): print(f\u0026#39;closure is generated, passed exponent : {exponent}\u0026#39;) def power(func): print(f\u0026#39;inner function in closure. passed func : {func}\u0026#39;) def inner_power(*args): print(f\u0026#39;inner function in power. passed args : {args}\u0026#39;) base = func(*args) return base ** exponent return inner_power return power # closure 생성 # raise_two = generate_power_with_debug(2) 와 동일 하다. @generate_power_with_debug(2) # power()를 리턴 def raise_two(n): # power()를 호출, inner_power()를 리턴 return n print(f\u0026#39;result of closure : {raise_two(7)}\u0026#39;) # 콘솔에 출력된 결과 closure is generated, passed exponent : 2 inner function in closure. passed func : \u0026lt;function raise_two at 0x100e2dee0\u0026gt; inner function in power. passed args : (7,) result of closure : 49 generate_power 호출 과정 (1)\n1 2 3 @generate_power_with_debug(2) def raise_two(n): return n raise_two = generate_power_with_debug(2) 와 동일하다. @generate_power_with_debug 데코레이터는 exponent 값을 포함한 내부함수 power를 리턴한다. raise_two가 선언되면서 power도 호출이 된다. power는 func를 포함한 내부험수 inner_function을 리턴한다. 여기에서도 inner_function은 호출되지 않고, 새로운 인스턴스를 생성해 리턴이 된다. generate_power 호출 과정 (2)\n1 print(f\u0026#39;result of closure : {raise_two(7)}\u0026#39;) raise_two를 호출하면서 클로저를 호출한다. 클로저 호출함에 따라 변수 *args에는 raise_two 함수에 전달된 인자 7이 전달된다. 이또한 스냅샷으로 외부 state를 저장했기 때문이다. 2-1. *args는 함수에 전달되는 모든 인자들을 뜻하고, **kwargs는 위치 지정된 모든 인자들을 뜻한다. inner_power 결과를 리턴한다. 클로저 VS 데코레이터 데코레이터는 클로저를 반환한다. 클로저는 데코레이터에 의해 반환된다. 이름에 _와 __사용 먼저 읽으면 좋을 자료 What’s the Meaning of Single and Double Underscores In Python? _ 와 __ 사용 예시\n1 2 3 4 5 6 7 _foo # single leading underscore foo_ # single trailing underscore _ # single underscore __foo__ # double leading and trailing underscore __foo # double leading underscore 상세 사용 예시 name e.g. usage single leading underscore _foo - private(internally) 하게 사용이 됨을 나타낸다. - 여전히 외부에서 접근이 가능하기 때문에 문맥적 힌트에 가깝다. single trailing underscore foo_ - 파이썬에서 이미 선점한 키워드를 사용할 때 혼선을 피하기 위한 방법이다.\ne.g. type_, from_ single underscore _ - 사용하지 않은 변수들을 담아두는 용도로 쓴다. e.g. _ = return_something(), - 숫자가 길어질 때 혼선을 방지하기 위해 쓴다. e.g. 1000 → 1_000 double leading and trailing underscore __foo__ - dunder method 라고 한다. - 파이썬에서 이미 선점한 특수 목적 전역 클레스 메소드다. double leading underscore __foo - 부모-자식 필드 이름을 구분하기 위해 사용되는 것으로 파악했다. - 실 사용이 거의 없을 거 같다. 파이 포장하기: 모듈, 패키지, 프로그램 모듈 파이썬을 사용하다보면 모듈이라는 단어가 자주 나오는데 여기서 모듈이란 단순히 파이썬 코드가 들어가있는 파일을 뜻한다.\n패키지 파이썬을 좀 더 확장 가능한 어플리케이션으로 만들기 위해서는 모듈을 패키지라는 파일 계층구조로 구성해야 한다. __init__.py 는 파일 내용을 비워놔도 되지만, 파이썬은 이 파일을 포함하는 디렉터리를 패키지로 간주 하기 때문에 패키지로 사용하고 싶다면 꼭 만들어둬야 한다.\n파이썬에서 batteries included 철학은 유용한 작업을 처리하는 많은 표준 라이브러리 모듈들이 내장이 되어있다는 뜻이다.\nDeque = Stack + Queue 파이썬 list는 left end의 pop()과 append()가 빠르지가 않기 때문에 left-end와 right-end 모두 빠르고 메모리를 효과적으로 사용하기 위해 데크를 제공한다.\nlist의 right-end 연산 속도는 O(1)이지만, left-end 연산 속도는 O(n)이다.\nDeque 구현체 Deque 는 Stack과 Queue의 기능을 가졌다. 출입구가 양 끝에 있는 Queue다.(double-ended queue의 구현체이다) Deque는 양 끝으로부터 항목을 추가하거나 삭제할 때 유용하게 쓰인다. popleft()는 left-end를 제거해서 반환하고, pop()은 right-end를 제거해서 반환한다. Deque 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from collections import deque numbers = deque([1,2,3,4]) \u0026gt;\u0026gt;\u0026gt; numbers.popleft() 1 \u0026gt;\u0026gt;\u0026gt; numbers.popleft() 2 \u0026gt;\u0026gt;\u0026gt; numbers deque([3,4]) \u0026gt;\u0026gt;\u0026gt; numbers.appendleft(2) \u0026gt;\u0026gt;\u0026gt; numbers.appendleft(1) \u0026gt;\u0026gt;\u0026gt; numbers deque([1,2,3,4]) Deque의 흥미로운 점 최대 길이 (maximum lenght)를 지정할 수 있다. 한 쪽에서 데이터를 넣어 큐가 꽉 차게 되면 자동으로 다른 쪽에 있는 아이템을 버린다. 이러한 기능으로 인해 이전 0회의 기록을 남기기 와 같은 요구사항이 있을 때 활용하기가 용이하다. [더 많은 Deque 사용법] 에서 더 많은 용도를 확인할 수 있다. 히스토리 남기기 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 from collections import deque sites = ( \u0026#34;google.com\u0026#34;, \u0026#34;yahoo.com\u0026#34;, \u0026#34;bing.com\u0026#34; ) pages = deque(maxlen=3) pages.maxlen for site in sites: pages.appendleft(site) \u0026gt;\u0026gt;\u0026gt; pages deque([\u0026#39;bing.com\u0026#39;, \u0026#39;yahoo.com\u0026#39;, \u0026#39;google.com\u0026#39;], maxlen=3) pages.appendleft(\u0026#34;facebook.com\u0026#34;) \u0026gt;\u0026gt;\u0026gt; pages deque([\u0026#39;facebook.com\u0026#39;, \u0026#39;bing.com\u0026#39;, \u0026#39;yahoo.com\u0026#39;], maxlen=3) pages.appendleft(\u0026#34;twitter.com\u0026#34;) \u0026gt;\u0026gt;\u0026gt; pages deque([\u0026#39;twitter.com\u0026#39;, \u0026#39;facebook.com\u0026#39;, \u0026#39;bing.com\u0026#39;], maxlen=3) Linux의 tail 모방 예시\n1 2 3 4 5 6 7 8 from collections import deque def tail(filename, lines=10): try: with open(filename) as file: return deque(file, lines) except OSError as error: print(f\u0026#39;Opening file \u0026#34;{filename}\u0026#34; failed with error: {error}\u0026#39;) thread-safe CPython에서 deque의 append(), appendleft(), pop(), popleft(), len()은 thread-safe 하게 만들어졌기 때문에 멀티쓰레드 환경에서 deque를 사용하기 좋다. CPyton은 C로 구현한 파이썬으로, 가장 많이 사용되고 있는 파이썬 구현체다. 오픈소스로 관리가 되고 있다. [깃허브] ","date":"2022-03-08","permalink":"https://leeleelee3264.github.io/post/2022-03-08-introducing-python-part-one/","tags":["Book"],"title":"[Introducing Python] part one (1/2)"},{"content":"\n터미널에서 여러 개의 깃허브 계정을 사용하는 방법을 다룹니다.\nIndex\n깃허브 계정 여러 개 세팅하기 매번 해줘야 하는 작업들 레퍼런스 깃허브 게정 여러 개 세팅하기 디렉터리 세팅하기 복수의 깃허브 계정을 사용 할 때, 각 계정들의 root source directory를 나누어두면 관리적 측면에서도, git config 설정을 할 때에도 더 편리하다.\n디렉터리 예시\n. └── home ├── office └── personal ssh 키 발급 Step 1 사용할 계정들의 키 발급 1 2 ssh-keygen -t rsa -b 4096 -C \u0026#34;leelee@office.com\u0026#34; ssh-keygen -t rsa -b 4096 -C \u0026#34;leelee@personal.com\u0026#34; Step 2 로컬의 ssh-agent 에 발급받은 키 연결: 1 2 ssh-add -K ~/.ssh/id_rsa_personal ssh-add -K ~/.ssh/id_rsa_office 위에서 연결한 ssh 키 정보들은 ssh-add -l 로 확인이 가능하다.\nStep 3 ssh config 작성 발급받은 키들과 깃허브 계정 정보를 로컬 단에서 연결을 하기 위해 .ssh/config 에 관련 정보들을 작성을 한다.\n.ssh/config\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Personal GitHub account Host github.com-personal HostName github.com User git AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/id_rsa # Office Github account Host github.com-office HostName github.com User git AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/id_rsa_office ssh 키 깃허브에 등록 ssh-keygen 결과물\nid_rsa.pub 외부로 공개되는 공개키이다. github에 등록되는 키다. 파일 끝을 보면 이메일을 확인할 수 있다. id_rsa 외부로 공개되면 안되는 비밀키이다. id_rsa.pub 에시\n1 2 3 4 5 6 7 8 9 10 11 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCruMY405yFL/6fvDvVFUTlxgXVO XRhdXlWDGsX5Kcn7yvEiGwBhVngvL8WWfA+hlelodoIAvlgnN9sJmVDDHF8XkK6r/ INdvFBAQ28+2GlOM8l038HDiCOTg/GzhEQK0hVzE0Cgsfrw2YMSxDJ9Gr9eSDSN0ia0LM LHMXdn5I5aeePGlt0boMIJgohzLVb4HT5KipBxbHETe05a8oOvmc9nS8r47ibSWpecuqDMJ7 7YrBa82X0d+5nAdZ1QiJg63k7ifJdPC4/CJHVvmglsHBzTkWEdn89R6q4OwyrUBRnrcITrF8 aCQMax2A5f7SaLcJ9xXQx47LT0ApfJ5UhHmLdK2vKzWEeEXhMfT3d0wIlppsEs5FuZRLqSAyZ QCn1IxZvV+KBAe5O3B9sidhULMnTzGqLCe3lLv3K0uI2MrP694LHqjW0duppbRbZZSNGdc0AM PtOqprI+lvBAugi6mN20sWRBMsHz1m1HdUI4yM85VAhYLNLgqs5n13ZfwUYEEh9EyqtGESToy 8DCSRqPqHNINB0skGBh9DF3ChjhdKvyn40AmpHdAzFlWgKGXbvx1DKzVhkubGNkISicwT7U+9 /18UuHJL2OsoFd9YcQ0qJqcrXWY2RxVkqAxzndxaPNeT5uXhZt0yNukm3UXd9khEd/Qn8F1n IqgHGiVCntP9wmQ== leelee@personal.com github setting 페이지로 이동 [Picture 1] Github Setting 메뉴바\nSSH and GPG Keys 항목에서 New SSH key 등록 office를 위한 id_rsa_personal.pub 와 id_rsa_office.pud 를 각각 등록해준다. [Picture 2] New SSH key 등록\n계정 정보 명시 Github에서 사용하는 name과 email을 별도로 설정해주지 않으면 개인 리포지토리에 올릴 커밋의 작성자가 회사 계정으로 되어있거나, 권한이 없다며 push를 할 수 없다. 떄문에 각각 계정별로 정보를 명시해줘야 한다.\n계정 정보 명시 시나리오 default: personal\nhome과 office 디렉터리에 각각 .gitconfig 파일을 하나씩 만들어준다. home의 .gitconfig에 personal 계정의 name과 email을 입력해준다. office 의 .gitconfig를 불러오는 설정을 추가해준다. office의 .gitconfig에 회사 계정의 name과 email을 입력해준다. home .gitconfig\n1 2 3 4 5 [user] name = leelee-personal email = leelee@personal.com [includeIf \u0026#34;gitdir:~/office/\u0026#34;] path = ~/office/.gitconfig office .gitconfig\n1 2 3 [user] name = leelee-office email = leelee@office.com 완성된 디렉터리 에시\n. └── home ├── .gitconfig ├── office │ └── .gitconfig └── personal 매번 해줘야 하는 작업들 레포지토리 주소 수정 .ssh/config 에서 연결할 Host를 계정별로 분기해서 각각 github.com-personal 과 github.com-office 로 구분을 했다. 때문에 매번 레포지토리를 만들거나, 클론할 때 구분하는 작업을 해줘야한다. git remote set-url 로 레포지토리를 연결할 떄도 똑같은 형식으로 해줘야 한다.\n기존 url\n1 git clone git@github.com:(Repo path).git 수정 url\n1 git clone git@github.com-office:(Repo path).git set-url 예시\n1 git remote set-url origin git@github.com-office:(Repo path).git Reference [CodeWords: A Mobile Application Blog by Heady]\n","date":"2022-01-12","permalink":"https://leeleelee3264.github.io/post/2022-01-12-git-multi-account/","tags":["General"],"title":"터미널에서 여러 개의 깃허브 계정 사용하기"},{"content":"\n2021 백엔드 엔지니어 인터뷰의 면접질문에 대해서 다룹니다.\nIndex\nPython DevOps 개발 전반 상식 Python 파이썬 쓰레드 파이썬 쓰레드에 대해 아는 점은 파이썬 자체에서 쓰레드를 지원하는 것은 아니고, 운영체제에서 제공하는 쓰레드를 사용한다는 것과, 쓰레드가 있다고 해도 한 타임에 한 쓰레드만 돌아간 다는 사실이었다. 이러한 특성의 원인은 파이썬의 디폴트 구현채인 CPython에 있었다.\nCpython 쓰레드 Cpython은 OS 쓰레드를 사용한다. 파이썬 쓰레드란, OS 쓰레드를 파이썬이 런타임에 관리를 하는 것 뿐이다. Cpython 인터프리터는 전역 인터프리터 록 (global interpreter lock) 메커니즘을 사용하여 한 번에 오직 하나의 스레드가 파이썬 바이트 코드를 실행하도록 보장한다.\n이런 인터프리터 전체를 잠구는 특성은 인터프리터를 다중스레드화 하기 쉽게 만든다, 하지만 한 번에 단 하나의 쓰레드를 실행시켜 쓰레드의 특징인 병렬성 잃어버리게 한다. (이는 multiprocessing 으로 보완)\n파이썬의 동시성과 병렬성 파이썬 쓰레드에 대해 너무 간략하게 알고 있었기 때문에 추가로 더 찾아보게 되었는데, 그때 프로그래밍에서 흔히 사용되는 개념인 동시성과 병렬성에 대해서, 또 파이썬은 이 둘을 어떻게 지원하는지 학습했다.\n원래는 동시성과 병렬성이 같은 뜻인줄 알았다. 알고보니 동시성은 짧은 시간에 한 가지 일을 처리 하고 금방 바꿔서 또 다른 일을 처리하는 걸 말한다. 결국 한 순간에는 한가지 일만을 처리하고 있다. 그런데 병렬성은 한 순간에 여러가지 일을 처리하고 있다.\n[Picture 1] 병렬성과 동시성\n그런데 병렬성이 빛을 보기 위해서는 정말로 CPU 여러 개가 있어야 한다. 여러 가지 CPU들에 일을 하나씩 할당해 마치도록 하기 떄문이다. 여러가지 일을 한 번에 처리하는 병렬성이 좋아보이지만, 어떤 일을 처리하냐에 따라서 동시성과 병렬성을 선택해야 한다. 대기하는 일이 대부분인 입출력 I/O 작업이라면 병렬을 해서 CPU를 놀게 하는 것보다는 동시성을 사용하는 게 더 효과적이다. 이제 실제 파이썬 구현 부분을 봐보도록 하자.\n동시성 장점 편리하고, 잘 이해되는 방법으로 다른 리소스들을 기다리는 테스크를 실행한다. 여기서의 리소스들은 네트워크, 입출력, 하드웨어 디바이스의 신호 등이 될 수 있다.\n단점 General한 쓰레드의 단점들처럼, 객체 엑세스를 잘 관리해줘야 해서 CPU에 민감한 작업은 할 수 없다. 또한 실행되고 있던 A 쓰레드가 B 쓰레드로 스위치 되면서 A 쓰레드는 멈춰버리기 때문에 쓰레드를 사용하는 퍼포먼스적 이점이 없다.\n동시성의 대표 예시: 코루틴 Python 코루틴 and async 예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import aiohttp import asyncio urls = [ \u0026#34;https://imdb.com\u0026#34;, \u0026#34;https://python.org\u0026#34;, \u0026#34;https://docs.python.org\u0026#34;, \u0026#34;https://wikipedia.org\u0026#34;, ] async def get_from(session, url): async with session.get(url) as r: return await r.text() async def main(): async with aiohttp.ClientSession() as session: datas = await asyncio.gather(*[get_from(session, u) for u in urls]) print ([_[:200] for _ in datas]) if __name__ == \u0026#34;__main__\u0026#34;: loop = asyncio.get_event_loop() loop.run_until_complete(main()) 코루틴 실행 시나리오\nget_from 함수가 코루틴이다. asyncio.gather 는 여러개의 코루틴 (다른 url들을 가진 다수의 get_from 함수 인스턴스) 를 생성해낸다. asyncio.gather 는 모든 코루틴이 실행 완료되기를 기다렸다가, 결과를 취합해서 리턴한다. 코루틴 장점 어떤 게 코루틴인지 문맥적으로 확실하게 구분을 할 수 있다. 쓰레드를 사용하면 어떤 함수도 쓰레드로 돌아갈 수 있어 혼동이 오는 데 코루틴은 그 점을 방지한다. 꼭 쓰레드를 필요로 하지 않는다. 코루틴은 파이썬 런타임이 직접 관리를 할 수 있다. 때문에 스위칭이 될 때에도 쓰레드보다 오버헤드도 작고, 메모리도 더 적게 필요로 한다. 코루틴 단점 async await 문법을 잘 지켜야 한다. 또한 쓰레드가 그러하듯, CPU에 민감한 작업은 할 수 없다.\n병렬성 말 그대로 프로세스를 여러 개 만드는 것이다. 각각의 CPU에서 돌아가기 때문에 멀티코어여야 한다. 프로세스를 여러개 만든 다는 말은 파이썬 인터프리터 인스턴스를 여러개 만든 다는 뜻이다!\n장점 쓰레드와 코루틴과는 다르게 객체의 다중 엑세스에 대한 관리가 조금 더 쉽다. 그리고 쓰레드와 코루틴은 다중 엑세스 때문에 모든 오퍼레이션이 순차적으로 돌아가게 하지만 이는 그럴 필요가 없다.\n단점 프로세스를 여러개 만드는 것 자체에 오버해드가 든다. 그리고 서브 프로세스들은 메인 프로세스에서 온 데이터 복사본이 있어야 하는데 이렇게 프로세스 사이에서 데이터가 왔다갔다 하기 위해서는 직렬화를 해야 한다. 이때 pickle 파이썬 라이브러리를 쓰는데, 보통의 객체들은 지원하지만 특이한 객체들은 지원을 하지 않는다.\n[Python concurrency and parallelism explained] 을 보면서 파이썬이 지원하는 동시성, 병렬성 구현을 살펴봤다.\n파이썬을 백엔드로 쓰면서 한꺼번에 몰린 요청을 처리하는 방법 이건 면접에서 나온 질문은 아니었고, 내가 궁금해서 물어본 부분이었다.\n파이썬은 인터프리터 언어다보니 백엔드로 사용을 하다보면 한계가 온다고 한다. 그래서 결국 컴파일 언어인 자바로 다시 만드는 경우가 왕왕있다고 하는데 한꺼번에 요청이 몰리면 어떻게 파이썬으로 처리를 하냐고 물어봤다.\n처리 방법 백엔드 코드를 쿠버네티스에 올려서 운용을 한다고 말씀해주셨는데, 그래서 요청이 몰릴때에도 이 쿠버네티스에 올린 파드를 증설한다고 한다. 즉, 컨테이너를 몇 개 더 만들어 요청을 분산처리 한다. 역시 코드 자체로 성능을 개선하기 보다는 돈을 써서 서버를 증설하는 방법이 회사에서 제일 많이 사용되는 방법이 아닐까.\nDjango 모듈 구조와 흐름 장고의 흐름은 [Picture 2] 같다. 굉장히 간단한 질문이었는데 장고를 거의 사용하고 있지 않아서 아주 뜨문뜨문 대답을 했다.. 한창 스프링을 쓰고 있었기 때문에 스프링에 빗대어서 대답을 했다.\n[Picture 2] Django 모듈 구조\nView Controller Model 데이터가 들어있는 엔티티 장고의 모델의 필드들은 db 테이블의 컬럼들과 매핑이 된다. db와 바로 연결이 되어있기 때문에 모델을 변경하면 자동으로 db에 migrate 될 수 있다. Template 화면이다. DRF라면 거의 쓸 일이 없다. Django wsgi 항상 프로젝트 안의 wsgi가 뭔가 했는데 웹 서버 및 어플리케이션을 위한 파이썬 표준이라고 한다.\n[Picture 3] wsgi 흐름\n클라이언트가 정적인 웹페이지를 요청했을 경우 웹서버에서 쳐 낼 수 있지만, 동적인 페이지를 요청했을 때는 웹서버에서 처리를 할 수 없고, 장고 서버에 리퀘스트를 넘겨줘야한다. 그런데 웹서버는 파이썬을 모른다. 그렇기 때문에 가운데에 wsgi가 인터페이스 역할을 해서 웹서버와 장고를 연결해준다.\n그럼 당연히 장고에서 제일 먼저 호출되는 부분은 wsgi가 될 수 밖에 없다. 얘가 리퀘스트를 물어다주니까. url 디스패처와 미들웨어 등등도 일단은 리퀘스트를 받아와야 해서 그 이후에 호출이 된다.\nDjango ORM objects.all objects.all 은 전체 자료를 불러온다. 모든 데이터가 필요하지 않은 이상 제일 효율이 좋지 않은 쿼리라 할 수 있다.\nselected_related VS prefetch_related Django ORM에서 쿼리 성능 향상으로 많이 쓰이는 기능은 select_related 와 prefetch_related인데 둘 다 즉시 로딩 (Eager-loading)과 한 번 DB에서 로딩을 한 이후부터는 캐싱이 되어서 쓰이는 등의 특징은 동일하지만 데이터를 가져오는 방식과 사용하는 상황이 조금 다르다.\n대게는 selected_related 사용을 추천하고 있다.\nselected_related one-to-one 같은 single-valued relationship 에서만 사용이 가능하다. DB에서 join을 해서 데이터를 가져온다. prefetch_related one-to-one 같은 single-valued relationship 에서 사용이 가능하다. many-to-many, many-to-one에서도 사용이 가능하다. DB에서 데이터를 가져올 때 2개의 단계를 거친다. 관계별로 개별 쿼리를 실행 (연결 테이블이 3개라면 3개의 쿼리가 따로 실행) 각각 가져온 데이터들을 파이썬에서 합쳐주기 참고하면 좋을 자료들 [select_related와 prefetch_related]\nselect_related와 prefetch_related에 대한 차이를 잘 설명해주고 있다. select_related와 prefetch_related를 함께 사용하는 방법도 있다. [당신이 몰랐던 Django Prefetch]\nDjango Prefetch 효율적 사용으로 성능개선하기 DevOps Nginx load balancing 스케쥴링 메서드 Round Robin 라운드 로빈은 운영체제 수업에서 배웠던 라운드 로빈과 동일한 알고리즘으로, 아무런 설정을 하지 않았다면 기본적으로 라운드 로빈 방식으로 스케쥴링이 된다. Least Connections 가장 적은 수의 active connection을 가지고 있는 서버에게 요청을 할당한다. IP Hash 똑같은 아이피에서 온 요청들을 똑같은 서버에서 처리할 수 있도록 보장한다. 동일 아이피의 기준은 IPv4일때는 앞의 3 옥텟이 동일해야 하고, IPv6에서는 모든 자리가 동일해야 한다. Generic Hash 유저가 정의한 키(hashed key value) 에 맞춰서 요청을 할당한다고 한다. 쿠버네티스 파드 쿠버네티스에서 생성하고 관리할 수 있는 배포 가능한 가장 작은 컴퓨팅 단위. 하나 이상의 컨테이너 그룹이다. 이 그룹은 스토리지 및 네트워크를 공유한다. 도커 개념 측면에서 파드는 공유 네임스페이스와 공유 파일시스템 볼륨이 있는 도커 컨테이너 그룹과 비슷하다.\nDocker Compose 도커를 실행하기 위해서는 도커 커맨드를 사용해야 하는데 간단한 커맨드는 상관이 없지만 볼륨을 연결하는 등의 추가 설정을 하다 보면 커맨드가 굉장히 길어진다. 이렇게 길어진 도커 커맨드를 쉘 스크립트로 짜도 되지만 이런 불편을 도커 컴포즈를 이용해 해결 할 수 있다.\n도커 컴포즈는 일종의 툴인데 도커 컨테이너 실행 환경을 YAML 파일로 관리할 수 있다.\n도커 컴포즈 예시\n1 2 3 4 5 6 7 8 9 10 11 version: \u0026#34;3.3\u0026#34; services: # db config web: build: . ports: - \u0026#34;4012:4012\u0026#34; environment: TZ: \u0026#34;Asia/Seoul\u0026#34; container_name: gov-prod-web_1 개발 전반 상식 DDD 디자인 패턴중 하나이다. Domain Driven Design의 약자이다. 보통 클린 아키텍처랑 함께 사용된다. 도메인 코드가 어플리케이션과 인프라 코드와 분리 되는 것에 집중을 한다는 점이 같기 때문이다. 도메인이란 프로젝트 안에서 개발되어야 하는 주제를 뜻하며, 비즈니스 로직이라 할 수 있다. 모든 소프트웨어 디자인 패턴의 목적처럼 시스템을 만들고 유지보수하는데 투입되는 인력 최소화에 있다. DDD 를 보다보면 유비쿼터스라는 단어가 많이 나온다. 개발자, 디자이너, 기획자가 모두 동일한 의미로 이해하는 단어라는 뜻이다. DDD 패턴은 비즈니스 로직인 도메인을 인프라와 어플리케이션(서비스) 와 분리하기 때문에 비즈니스 자체에 집중을 할 수 있다. 그래서 개발자가 다른 부서와 협업을 할 때 의사소통이 더 원활하게 이뤄질 수 있다. (db, network 등등의 로우 레벨 을 얘기하지 않기 때문)\n[Picture 4] Layer of the Clean Architecture\n도메인 개념에 집중해서 아키텍처를 만들면 [Picture 4] 와 같다. 도메인 속에 엔타티가 들어있는데 이게 제일 중요한 개념이라고 생각한다. 엔티티에 최대한 많은 비즈니스 룰을 담아서 응집성을 높이고, 중복코드를 줄이는게 ddd의 목표이다. 단! 엔티티 밖의 메소드 (예를 들어 어플리케이션 레이어) 가 엔티티의 값을 변경하는 일은 절대 없어야 한다. 이는 객체지향에서 추구하는 캡슐화와 유사하다고 볼 수 있다.\n엔티티의 일은 엔티티 안에서 끝이 나야 한다! validation 조차도 UseCase에서 호출하면 안되고, 비즈니스를 제일 잘 아는 Entity에서 검증해야 한다.\n[Picture 5] Entity Anti Pattern\nMVC 패턴에서도 DDD에서도 서비스의 역할을 정하는 게 가장 어렵다. 조금만 잘못해도 코드가 서비스에 치중을 해 결국 서비스에서 엔티티의 값도 바꾸고, DB에 저장 요청도 하는 거대한 서비스 중심이 될 수 있기 때문이다. DDD 에서 서비스 (또는 use case) 의 역할은 여러가지 엔티티가 함께 다뤄져야 할 때이다. (여러가지 엔티티가 함께 다뤄지지 않아도 Controller 영역에서 바로 엔티티를 호출해서는 안된다)\nDAO와 DTO, ENTITY DAO DAO는 Data Access Object 로, 데이터에 엑세스하기 위한 객체다. 정말 데이터를 얻어오기 위해 접근을 하는 객체라 다른 말을 할 것이 없다. DAO 볼때마다 드는 생각이 그럼 Repository 는 뭐지? 둘의 차이는 [Picture 6] 와 같다.\nDAO VS Repository 레포지토리가 더 상위계층이고 DAO가 하위계층이다.\n레포지토리는 도메인과 데이터 매핑 레이어 가운데에 있는 존재이다. DAO 는 말 그대로 못생긴 쿼리를 한 번 숨기는 역할을 하고, 레포지토리는 여러가지 DAO를 활용해서 데이터를 상위 계층으로 전달을 할 수 있다.\n[Picture 6] DAO and Entity\nDTO DTO는 Data Transfer Object로, 데이터를 여러 계층 사이로 전송하기 위한 객체다. 스프링관점으로 생각을 해보자면 DAO가 DB에서 가져온 정보를 서비스 계층으로 넘길 때 DTO 에 넣어서 전송을 하고, 서비스 계층이 컨트롤러 계층으로 넘길 때 DTO를 사용한다 .\nEntity Entity 는 DDD의 관점에서 보면 비즈니스 로직이고, JPA로 보면 DB테이블 그 자체이다. 이렇게 중요한 부분 그 자체이기 때문에 변경도 엔티티 안에서 일어나야 하고, 다른 계층으로 넘길때도 그냥 넘겨서는 절대 안된다. 꼭 DTO에 담아서 전달을 해 줘야 한다.\nRequest Method GET 데이터를 조회하기 위한 요청이다. 몇번을 반복적으로 요청해도 받아보는 데이터에 변화가 없다는 게 중요한 점이다. 이런 GET의 성격 때문에 무엇인가를 바꾸려는 작업을 GET으로 만들지 말아야 한다. POST POST는 무엇인가를 바꾸기 (update/insert/delete) 위한 요청이다. 같은 요청을 여러번 날리다보면 사이드 이펙트가 발생할 수 있다. GET VS POST POST가 GET보다 보안상 안전하다. GET은 URL안에 모든 정보를 다 포함하고 있기 때문에 웹서버 등지에서 엑세스 로그를 남길 경우 GET에 있던 정보들이 그대로 남게 된다. 하지만 POST 또한 데이터를 URL에 넣지 않고 body에 넣었단 차이만 있을 뿐이고, 이 body도 까서 볼 수 있기 때문에 마냥 안전하다고 볼 수 없다. 민감한 데이터는 어지간하면 네트워크를 타고 움직이지 않는 것이 제일 좋다. 멱등성 이렇게 GET처럼 똑같은 요청(연산)을 여러번 하더라도 결과가 달라지지 않는 성질을 멱등성(Idempotent)라고 한다. Rest api에서 제일 많이 사용되는 메서드들 중에서 POST를 제외한 GET, PUT, DELETE은 멱등성을 지켜야 함을 명심하면서 서버 구현을 하도록 해야 한다.\n[Picture 7] HTTP Method\nPOST VS PUT 처음에 HTTP 메서드들을 배웠을 때 POST와 PUT 구분이 어려웠다. 결국 POST나 PUT 둘 다 CREATE이 가능하기 때문에. 그런데 찾아보니 아래와 같은 사항으로 구분을 할 수 있었고, 다시 고려해보면 PUT은 CREATE 보다는 UPDATE에 더 적합해 보인다.\n시나리오 1: 멱등성을 유지해야 하는가?\nPOST = (a++) ⇒ 계속 1이 증가하여 결과 값이 매번 달라진다. PUT = (a=4) ⇒ 계속 a는 4로 업데이트 되기 때문에 결과값이 매번 같다. 시나리오 2: 리소스 결정권이 있는가?\n리소스 결정권은 클라이언트가 이 리소스의 위치 (리소스 id)를 정확히 아는지 모르는지의 차이다.\nPOST /articles PUT /articles/11120 PUT 클라이언트가 리소스가 어디에 저장이되는지 정확히 알 수 있다. 내가 많이 쓰던 POST의 path variable 이 들어간 URL이 사실은 PUT에 맞는 컨벤션이었다. POST POST는 해당 URL을 요청하기만 하면 원하는 리소스를 만들어주겠다며 factory만 제공해주고 리소스의 정확한 위치는 제공하지 않고 있다. PUT VS PATCH 둘 다 리소스를 업데이트 한다는 느낌이 강하지만 작은 차이가 있다.\nPUT은 리소스 전체 또는 다수를 업데이트 하는 느낌이 강하다. PATCH는 리소스의 일부 또는 단 하나를 업데이트 하는 느낌이 강하다. Cross Origin Resource Sharing CORS의 정확한 개념 줄여서 CORS라고 한다. 위키사전에서 찾아봤을 때 교차 출처 리소스 공유라고 직역을 하고 있다.\n원래 내가 알고 있던 부분은 같은 출처가 아닌, 다른 출처에서 리소스 요청을 했을 때 보안상 요청을 처리하지 못하고 error를 보낸다 였다. 그래서 이 문제를 해결하기 위한 정책이 CORS이고. 그런데 내가 심각하게 오해하고 있던 부분은, 여기서의 Origin이 서버를 의미하는 게 아니라 요청을 보낸 클라이언트를 의미하는 것 이었다.\n브라우저에 치중되어 있는 CORS RFC에 존재하는 리소스 요청 정책은 2가지 이다. 하나는 SOP (Same-Origin Policy) 이고 다른 하나는 CORS이다. 하지만 이 정책들은 브라우저에민 구현되어있는 스펙이다.\n서버와 서버가 리소스를 주고 받을 때는 CORS 문제가 발생하지 않는다. 서버에서 응답을 주더라도 브라우저 단에서 응답을 막고 error를 내려준다. 때문에 서버 로그에서는 정상적으로 응답이 내려갔다고 보이며 디버깅이 상당히 어려워진다. 때문에 서버에서도 CORS의 존재에 대해 염두해 두고 있어야 한다!\n[Picture 8] CORS\n[Picture 8] 의 설명이 제일 명확했다. 브라우저는 스크립트가 요청을 보낼 때 지금 스크립트가 서비스 되고 있는 url과 요청을 보내는 url을 비교한다. 여기서 동일한 url로 보여지는 조건은 프로토콜/스키마 (https, http) 와 호스트 (www.google.com) 포트번호가 모두 같을 때 동일한 url로 인정한다.\nCORS 발생 시나리오 Preflight Simple Request Credentialed Request 어떻게, 어떤 조건에서 헤더를 채워서 보내는지에 따라 브라우저가 임의로 하나의 시나리오를 보내 요청을 보낸다. 어떤 조건속에서 어떤 CORS 시나리오가 만들어지는지 잘 유념하자.\nCORS 해결 방법 클라이언트에서 발생하는 문제이지만 이걸 해결하기 위해서는 서버가 작업을 해야 한다. 해당 리소스에 대해 어떤 origin들이 요청을 할 수 있는지 응답 헤더중 하나인 Access-Control-Allow-Origin에 기입을 해주는 것이다. 여기에 와일드 카드를 넣어버릴 수 있지만 이럼 언제나 보안 문제가 일어날 수 있음을 명심하자. Access-Control-Allow-Origin에 들어있는 Origin들과 요청을 보냈던 클라이언트의 Origin을 보고 브라우저가 유효한 응답임을 판단한다.\nOptions Method Options 메소드가 언제 쓰이는지 궁금했었는데 이렇게 Access-Control-Allow-Origin 을 알기 위해 선행 요청을 보낼 때도 사용이 된다고 한다.\n[Picture 9] Options Method\n참고하면 좋을 자료들 [Cross Origin Resource Sharing - CORS] [CORS는 왜 이렇게 우리를 힘들게 하는걸까?] Authentication 과 Authorization의 차이 Oauth2에 대해 대답을 하다가 나온 문제였다. 둘이 어떤 개념인지는 알지만 용어적으로 낯설어 제대로 대답을 하지 못 해 이번에 정리를 하면서 찾아봤다. Authentication과 Authorization을 쉽게 비교하기 위해 표를 작성했다.\n/ Authentication Authorization 역할 사용자 신원 확인 리소스, 기능 에 대한 엑세스 권한 확인 목적 사용자가 누구인지 확인/판별 사용자가 해당 리소스/기능에 대해 사용 권한이 있는지 확인/판별 방법 로그인, 생체인식 session key, JWT, Oauth 절차는 Authentication ➡️ Authorization 이 이루어진다고 보면 된다.\nAuthentication이 되었다고 해도 보내는 리퀘스트마다 이 사용자가 정말로 자격이 있는지 매번 확인을 하는 절차가 Authentication이라고 생각한다.\n스키마를 짤 때 하는 고민 이건 정말 광범위한 범위가 아닐까? 아직도 어떤 방식으로 스키마를 짜는 게 최적인지 잘 모르겠다. 정말 서비스마다 다른 것 같다. 내가 스키마를 짜면서 확실하게 느꼈던 부분 정도만 정리를 했다.\n높은 수준의 정규화를 했을 때는 조회를 할 때 JOIN을 많이 해줘야 하지만 데이터 수정과 삭제가 용이하다. 낮은 수준의 정규화를 했을 때는 조회할 때 JOIN을 많이 안 해줘도 된다. 그러나 중복된 데이터가 많아진다. 옛날에는 하드가 비싸서 정규화에 신경을 많이 썼는데 요즘은 하드가 비싸지 않아 정규화를 많이 할 필요가 없다고 한다. 히스토리 처럼 아래로 쌓이는 데이터의 경우 높은 수준의 정규화를 하지 않아도 된다. UPDATE가 자주 일어나는 데이터인지 INSERT가 많이 일어나는 데이터인지에 따라서 스키마가 달라질 필요가 있다. 고수준 인터페이스와 저수준 인터페이스 고수준 인터페이스와 저수준 인터페이스라는 단어보다는 고수준 모듈, 저수준 모듈 이라는 말을 더 많이 사용한다.\n고수준 모듈 추상화가 되어있는 기능을 제공한다. 1 2 3 public interface Animal { void eat(); } 저수준 모듈 고수준에서 제공하는 기능을 실제로 구현한다. 1 2 3 4 5 6 public People implements Animal { @Override void eat() { Systems.out.println(\u0026#34;People eat many things\u0026#34;); } 여태 고수준과 저수준을 반대로 생각하고 있었다. 고수준이 실제로 구현이 된 부분이고 저수준이 추상화의 부분인줄 알았으나 실제는 반대였다.\n","date":"2022-01-01","permalink":"https://leeleelee3264.github.io/post/2022-01-01-interview-python/","tags":["General"],"title":"2021 백엔드 엔지니어 인터뷰 - Python, General"},{"content":"\n2021 백엔드 엔지니어 인터뷰의 면접질문에 대해서 다룹니다.\nIndex\nIntro 기술면접 회고 Java Intro 10월 달 부터 이직을 준비하기 시작하며 Resume 와 Cover Letter 를 썼고, 11월 달에는 면접을 보러 다녔다. 대부분의 면접들이 몇 단계로 이루어져있었는데 기술 면접에서 면접관들이 물어봤던 질문들을 기록해두고 공유하면 좋을 것 같아 포스팅을 하기로 했다.\n지원분야가 Backend이기 때문에 대부분의 질문들이 Backend 와 관련이 되어있지만, 직전에 근무하고 있던 회사에서 DevOps의 경험도 있다고 이력서에 적어서 DevOps와 관련된 질문들도 약간 있었다. 깃허브에 [DevOps 커리큘럼]이 있는데 면접 때 보고 가면 도움이 될 거 같다.\n기술면접 회고 커리어를 시작하고 이렇다 할 면접들을 보러 다닌적이 없었는데 기술면접을 보고 나니 왜 기술 공부를 더 열심히 해야 하는지 깨달았다. 이론적인 측면들은 지루해서 공부를 피하기 마련이었는데 기술면접에서 다 물어보는 것들이었고, 결국은 이 이론적인 측면들을 잘 알아야지만 더 좋은 코드를 만들 수 있다.\n깊이는 없는 새로운 기술에 대한 욕심 파이썬을 그냥 써보기만 했고 깊이가 없었다. 다른 개념들도 마찬가지였다. 막 커리어를 시작했을 때는 이것저것 조금씩 공부하는 게 좋았는데 이제는 깊이가 있는 공부를 해야하는 때가 아닌가 싶다.\n퇴사를 준비하면서 이것저것 많이 여쭤봤던 팀장님께 인사를 드렸는데 기술에 대한 욕심을 조금 버리는 게 좋다고 조언해주셨다. 그도 그럴게 2년 동안 정말 신기술에 집착을 많이 했던 것 같다\u0026hellip; 그 분이 항상 해주시던 말씀이 프레임워크를 공부하기보다는 언어를 더 공부하라 였는데 결국 기본기가 제일 중요한 게 아닐까? 디자인 패턴과 정규식은 어디에서도 쓰이는 것처럼.\n빨리 사둔 디자인 패턴 책도 읽고 이팩티브 자바도 다시 읽어봐야겠다. 자바 빨리빨리 공부하고 파이썬으로 진짜 넘어가야지!\n면접 질문 추이 이력서에 주로 사용하던 언어가 자바라고 썼기 때문에 자바 질문이 들어왔고 면접을 본 회사들은 대부분 파이썬을 사용하고 있었기 때문에 파이썬 질문도 많았다. 질문의 구성은 크게 아래와 같았다.\n자바 질문 파이썬 질문 개발 전반 상식 이번 포스팅에서는 자바 질문과 답변을 다룬다.\nJava 실행중인 Spring Boot에서 변경된 properties 로드하기 맨 처음에는 Spring boot에서 properties 를 적용하는 방법에 대한 질문인 줄 알고 Spring boot externalized properties 우선순위에 대해 답변했는데 아니었다. 이미 러닝중인 서버에 수정된 propreties를 재시작없이 어떻게 반영하냐에 대한 질문이었다.\nSpring Boot Actuator Spring Boot Actuator 를 이용하면 된다. 이렇게 config 를 러닝 타임에 업데이트 하는 상황은 서버가 하나 떠있을 때 보다는 서버를 여러 개 띄워두는 Spring Cloud 환경에서 많이 사용하는 것으로 보인다.\n[Picture 1] Spring Cloud Config\nSpring Cloud Config는 Spring Cloud Config 서버와 클라이언트 어플리케이션 ([Picture 1] 에서 Microservice #1 #2 #3 로 표기된 서버들) 로 구성이 되어있는데 config 서버 설정에 변경이 생겼을 때 클라이언트 어플리케이션도 변경을 반영해줘야 한다. 이때 다시 시작하지 않고 actuator 를 이용해서 refresh 하면 된다.\n여기서 actuator 는 실행중인 스프링 어플리케이션 내부 정보를 REST 엔드포인트와 JMX MBeans(Java Management Extension. 모니터링용 객체) 로 노출시키는 스프링 부트의 확장모듈이다. 실행중인 스프링 어플리케이션을 뜯어 볼 수 있다는 게 중요하다!\nSpring Boot Actuator 사용법 클라이언트 어플리케이션에 actuator 라이브러리를 implement 한다. 클라이언트 어플리케이션 application.properties또는 application.yml 에 actuator 사용을 위한 설정을 추가 한다. Config 서버에서 가져온 설정을 사용하는 코드 부분에 @RefreshScope 추가 한다. http://클라이언트서버/actuator/refresh POST 호출로 변경사항 적용한다. 참고하면 좋을 자료들 [Spring cloud config 리프래시 하기 (Use RefreshScope)] [Spring Cloud Config 2] JDBC Java Database Connectivity의 약자이다.\n데이터베이스 연결을 관리하는 자바 API로, 쿼리와 커맨드를 발행하고 데이터베이스에서 건내주는 결과 셋을 처리한다. JDBC는 자바 어플리케이션이 데이터베이스 또는 RDBMS와 소통하기 위한 프로그래밍 레벨 인터페이스를 제공한다.\n[Picture 2] JDBC 상세\nJDBC는 결과적으로 자바 코드로 데이터베이스를 관리할 수 있게 만들어준다. JDBC API는 자바 어플리케이션과 JDBC Manager 사이의 커뮤니케이션을 지원한다. JDBC Driver는 데이터베이스와 JDBC Manager 사이의 커뮤니케이션을 지원한다. 직렬화 직렬화는 객체를 바이트 스트림으로 바꾸는 것이다. 이와 반대로 바이트 스트림을 객체로 바꾸는 것은 역직렬화라고 한다.\n객체는 플랫폼에서 독립적이지 못하다. 그래서 [Picture 3] 처럼 파일, 메모리, 데이터베이스 처럼 다른 시스템으로 보내려고 할 때 플랫폼에서 독립적인 바이트 스트림으로 변환을 한다.\n[Picture 3] 직렬화란?\n자바 직렬화 자바 직렬화도 마찬가지로 JVM 메모리에 올라가있는 객체를 byte 스트림 (byte 형태의 데이터) 바꾸는 것이다.\n[Picture 4] 자바 직렬화 상세\n그런데 요즘의 API들을 생각해보면 데이터를 다 JSON으로 직렬화 해서 내보내고 있다. JSON 처럼 문자열로 변환하는 형태가 아니라 이진 표현으로 변환해서 내보낼때는 Protocol Buffer를 사용한다고 한다. 그럼 손쉬운 JSON과 Protocol Buffer가 아니라 번거로운 자바 직렬화를 사용할 때의 장점은 무엇일까?\n자바 직렬화 장점 자바 직렬화의 장점은 자바에 최적화 되었다는 점이다. 자바 시스템에서 또 다른 자바 시스템으로 데이터를 보낼 때 손쉽게 직렬화-역직렬화를 할 수 있다. 서블릿 세션이 대표적인 사용처라고 하는데 홈페이지를 만들때도 유저의 로그인 세션을 직렬화해서 관리했던 게 생각이 난다.\n자바 직렬화 문제점 외부에 나가서 장기 보관될 정보는 자바 직렬화를 사용하지 않는다. 추후에 변경이 있으면 오류가 나기 때문이다. 자바 직렬화에 사용하는 시리얼 ID도 개발시에 따로 관리를 해줘야 한다. 직렬화-역직렬화를 할 때 타입과 필드의 변경에 엄격해 오류가 잘 발생할 수 있다. 때문에 자주 변경되는 클래스는 자바 직렬화를 사용하지 않는 것이 좋다. 자바 직렬화된 데이터는 JSON 보다 훨씬 크기가 크다. 떄문에 직렬화된 데이터를 캐시등의 이유로 존재하는 Redis 와 같은 메모리 서버에 저장을 하면 트래픽에 따라 비용이 급증할 수 있다. 위와 같은 이유들로 최대한 JSON 포맷으로 변경을 고려해야 한다. 참고하면 좋을 자료들 [자바 직렬화, 그것이 알고싶다. 훑어보기편] 저번에 FCM으로 보낼 푸시 메세지들을 직렬화해서 Redis 메모리에 넣어두어 어플리케이션 서버에서 큐 구조로 순차적으로 꺼내갈 수 있게 해뒀는데 이번에 직렬화를 찾아보니 JSON으로 바꾸는 방향으로 해야겠다..\nInterface와 Abstract class의 차이 추상 클래스와 인터페이스 모두 선언만 가능하고, new 를 사용해서 인스턴스를 만드는 게 불가능하다는 공통점이 있지만, 차이점이 더 많다.\nInterface 인터페이스는 A is able to B 를 만족시킨다. 인터페이스는 자바8, 9에 들어오면서 원래의 인터페이스에서 많은 변화가 생겼다.\nInterface의 변화 추상메서드만 만들 수 있었으나 JAVA 8에 들어오면서 default를 사용해 메서드 구현이 가능해졌다. 필드를 가질 수 없었으나 JAVA 8에 들어오면서 final 과 static 필드를 가질 수 있게 되었다. 접근 지정자가 default로 private 이었으나 JAVA 9에 들어오면서 private 사용도 가능해졌다. Abstract class 추상클래스는 A is B를 만족시킨다. 추상메서드를 만들 수 있고, 구현이 된 메서드를 만들 수 도 있다. 일반 클래스와 마찬가지로 필드도 가질 수 있다.\nAbstract class 사용시 주의 점 실무에서 추상클래스를 사용했는데 상속관계를 제대로 고려하지 않았었기 때문에 모두 리팩토링을 해야 했다. 추상클래스를 사용을 할 때에는 super 클래스와 하위클래스의 관계를 잘 생각해서 구현을 해야 하고, 추상클래스 보다는 인터페이스 사용을 권장한다.\nDI, IOC Dependency Injection과 Inversion Of Control. Spring에서 처음 접한 개념인데, Spring 뿐만 아니라 다른 언어와 프레임워크에서도 널리 사용되는 개념이다.\nIoC는 설계 원칙이고 DI 는 IoC 원칙을 지키기 위한 디자인 패턴이다. 실제로 DI 말고도 IoC를 위한 다양한 패턴이 존재한다.\n[Picture 4] IoC Pattern 구현 방법론\nIoC IoC는 객체 사이의 결합도를 줄이기 위해 제어를 역전시킨다. 가장 흔한 제어의 역전의 예시로는 객체 생성이 있다. 제어 역전이 일어나면 객체를 직접 생성하지 않고, 이미 생성되어 있는 코드를 사용하기만 한다.\nSpring으로 예를 들어보면 Bean으로 선언된 객체들은 Spring에서 관리를 한다. Bean 객체들은 IoC Container 안에 생성이 되고, 관리가 된다. 우리는 그 객체들이 어떻게 관리가 되고 있는지 알 필요 없이 해당 객체를 사용해야 할 때 의존성을 주입받아 (DI) 사용을 하면 된다.\nDI DI는 의존성 있는 객체의 생성을 class 외부에서 수행한 후, 다양한 방법으로 해당 객체를 class 에게 제공한다.\nDI 예시\n1 2 3 4 5 6 7 8 9 10 @Controller public class TestController { private final TestService testService; public TestController(TestService testService) { this.testService = testService; } } DI을 이용해 객체 결합도를 느슨하게 하기 위해서는 Client, Service, Injector 클래스가 필요하다. Injector 클래스가 Service 객체를 만들어 Client 클래스에 제공하는 형태인데 코딩을 하면서 무수히 많은 객체들의 의존성을 매번 이렇게 만들어 줄 수는 없다.\n때문에 IoC Container와 같은 기능을 제공하는 프레임워크를 사용해 위와 같은 일을 위임한다. 프레임워크를 사용하면 객체의 의존도를 고려하면서 객체의 생성. 소멸을 신경쓰지 않아도 되고 비즈니스 코드에 더 집중을 할 수 있고 결과적으로 변경에 유연한 코드를 만들 수 있다.\n참고하면 좋을 자료들 [Dependency Injection, IoC, DIP, IoC container정리] Static static 키워드를 사용한 메서드와 변수는 해당 클래스의 객체를 생성하지 않아도 해당 메서드와 변수를 사용할 수 있다. 매번 객체를 생성하지 않아도 되기 때문에 손쉽게 사용을 할 수 있어 내 경우는 Utill 성 메서드들을 static으로 만들었다.\nstatic 의 특징 static은 메모리에 딱 한 번 할당이 된다. 일반적인 객체들이 Heap 영역에 할당이 되는 것과는 다르게 stack 영역에 만들어진다. 때문에 Heap 처럼 Garbage Collection을 걱정하지 않아도 된다. stack 은 모든 객체가 공유하는 메모리 공간이기 때문에 객체 생성이 없이도 static 메서드와 변수를 사용할 수 있다. Java8에서의 static Java 8이전에 static 변수와 메서드는 JVM 메모리에서 PermGen에 저장이 되었으나 Java 8에서는 PermGen 가 사라지고 MetaSpace가 그 역할을 대신한다. 변경된 Java 8 JVM 구조는 [Picture 5] 와 같다.\n[Picture 5] IoC Pattern 구현 방법론\nstatic 핵심 구현 사항 인스턴스 변수 (non-static) 를 사용하는 메서드는 인스턴스 메서드를 사용하고 클래스 변수 (static) 을 사용하는 메서드는 static 메서드를 사용한다.\n클래스를 설계할 때 인스턴스에 공통적으로 사용해야 하는 맴버변수에 static을 사용한다. static 메서드에서는 static이 아닌 맴버변수는 사용할 수 없다. static 이 아닌 메서드에서는 static인 맴버변수를 사용할 수 있다. 메서드 안에서 인스턴스 변수를 사용하지 않는다면 static을 사용을 고려한다. 1과 같은 특성으로 한 인스턴스에서 static 변수의 값을 바꿨을 때 모든 인스턴스에 변경이 적용된다. 이와 같은 모두 변경 불상사를 피하기 위해서 static 변수를 사용할 때 final 키위드를 함께 사용해 변경을 불가하게 만든다.\n2, 3과 같은 일이 일어나는 이유는 인스턴스 변수가 static 변수 또는 메서드를 사용하는 시점에서는 static 변수와 메서드가 이미 생성이 되어있지만 반대의 경우에는 사용 시점에 인스턴스가 만들어졌는지 알 수 없기 때문이다.\n","date":"2021-12-02","permalink":"https://leeleelee3264.github.io/post/2021-12-02-interview-java/","tags":["General"],"title":"2021 백엔드 엔지니어 인터뷰 - Java"}]